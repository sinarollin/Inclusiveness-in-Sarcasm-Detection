{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import pandas as pd\n",
    "from nltk.corpus import wordnet\n",
    "import nltk\n",
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the sarcasm data textual representation\n",
    "\n",
    "file_path = \"sarcasm_data.csv\"\n",
    "\n",
    "# Loading the CSV file into a DataFrame\n",
    "\n",
    "df_text = pd.read_csv(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>utterance</th>\n",
       "      <th>speaker</th>\n",
       "      <th>context</th>\n",
       "      <th>context_speakers</th>\n",
       "      <th>show</th>\n",
       "      <th>sarcasm</th>\n",
       "      <th>gender</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>It's just a privilege to watch your mind at work.</td>\n",
       "      <td>SHELDON</td>\n",
       "      <td>['I never would have identified the fingerprin...</td>\n",
       "      <td>['LEONARD', 'SHELDON']</td>\n",
       "      <td>BBT</td>\n",
       "      <td>True</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I don't think I'll be able to stop thinking ab...</td>\n",
       "      <td>PENNY</td>\n",
       "      <td>['This is one of my favorite places to kick ba...</td>\n",
       "      <td>['HOWARD', 'PENNY', 'HOWARD', 'HOWARD', 'HOWAR...</td>\n",
       "      <td>BBT</td>\n",
       "      <td>True</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Since it's not bee season, you can have my epi...</td>\n",
       "      <td>SHELDON</td>\n",
       "      <td>['Here we go. Pad thai, no peanuts.', 'But doe...</td>\n",
       "      <td>['LEONARD', 'HOWARD', 'LEONARD']</td>\n",
       "      <td>BBT</td>\n",
       "      <td>False</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Lois Lane is falling, accelerating at an initi...</td>\n",
       "      <td>SHELDON</td>\n",
       "      <td>['A marathon? How many Superman movies are the...</td>\n",
       "      <td>['PENNY', 'SHELDON', 'PENNY', 'SHELDON', 'SHEL...</td>\n",
       "      <td>BBT</td>\n",
       "      <td>False</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I'm just inferring this is a couch because the...</td>\n",
       "      <td>SHELDON</td>\n",
       "      <td>[\"Great Caesar's ghost, look at this place.\", ...</td>\n",
       "      <td>['SHELDON', 'LEONARD', 'SHELDON', 'SHELDON', '...</td>\n",
       "      <td>BBT</td>\n",
       "      <td>True</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           utterance  speaker  \\\n",
       "0  It's just a privilege to watch your mind at work.  SHELDON   \n",
       "1  I don't think I'll be able to stop thinking ab...    PENNY   \n",
       "2  Since it's not bee season, you can have my epi...  SHELDON   \n",
       "3  Lois Lane is falling, accelerating at an initi...  SHELDON   \n",
       "4  I'm just inferring this is a couch because the...  SHELDON   \n",
       "\n",
       "                                             context  \\\n",
       "0  ['I never would have identified the fingerprin...   \n",
       "1  ['This is one of my favorite places to kick ba...   \n",
       "2  ['Here we go. Pad thai, no peanuts.', 'But doe...   \n",
       "3  ['A marathon? How many Superman movies are the...   \n",
       "4  [\"Great Caesar's ghost, look at this place.\", ...   \n",
       "\n",
       "                                    context_speakers show  sarcasm gender  \n",
       "0                             ['LEONARD', 'SHELDON']  BBT     True      M  \n",
       "1  ['HOWARD', 'PENNY', 'HOWARD', 'HOWARD', 'HOWAR...  BBT     True      F  \n",
       "2                   ['LEONARD', 'HOWARD', 'LEONARD']  BBT    False      M  \n",
       "3  ['PENNY', 'SHELDON', 'PENNY', 'SHELDON', 'SHEL...  BBT    False      M  \n",
       "4  ['SHELDON', 'LEONARD', 'SHELDON', 'SHELDON', '...  BBT     True      M  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_text.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/g0/lpk94w2x1bz7lsmcbjl0vrsc0000gn/T/ipykernel_67965/1461413170.py:32: UserWarning: [W007] The model you're using has no word vectors loaded, so the result of the Doc.similarity method will be based on the tagger, parser and NER, which may not give useful similarity judgements. This may happen if you're using one of the small models, e.g. `en_core_web_sm`, which don't ship with word vectors and only use context-sensitive tensors. You can always add your own word vectors, or use one of the larger models instead if available.\n",
      "  similarity = word_nlp.similarity(synonym_nlp)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Utterance: I'm just inferring this is a couch because the evidence suggests the coffee table is having a tiny garage sale.\n",
      "Augmented Utterance: I 'm just inferring this is a couch because the evidence suggests the coffee table is having a diminutive garage sale .\n"
     ]
    }
   ],
   "source": [
    "INCLUDED_POS_TAGS = {\"VERB\", \"NOUN\", \"ADJ\"}  # Include only verbs and nouns\n",
    "\n",
    "def get_synonyms(word):\n",
    "    synonyms = set()\n",
    "    for synset in wordnet.synsets(word):\n",
    "        for lemma in synset.lemmas():\n",
    "            synonyms.add(lemma.name())\n",
    "    return list(synonyms)\n",
    "\n",
    "def replace_with_synonyms(sentence):\n",
    "    doc = nlp(sentence)\n",
    "    new_sentence = []\n",
    "\n",
    "    for token in doc:\n",
    "        if token.text.isalpha() and not token.is_stop and token.pos_ in INCLUDED_POS_TAGS:\n",
    "            \n",
    "            synonyms = [token.text]  # Starting with the original word\n",
    "            \n",
    "            # Finding synonyms from WordNet\n",
    "            word_synonyms = get_synonyms(token.text)\n",
    "\n",
    "            if word_synonyms and len(word_synonyms) > 1:\n",
    "                \n",
    "                # Selecting the second synonym. The first is often the word itself, whilst later synonyms are further away concerning similarity.\n",
    "                synonym = word_synonyms[1]\n",
    "\n",
    "                word_nlp = nlp(token.text)\n",
    "                synonym_nlp = nlp(synonym)\n",
    "\n",
    "                # Checking the similarity between the original word and the proposed synonym\n",
    "\n",
    "                similarity = word_nlp.similarity(synonym_nlp)\n",
    "\n",
    "                # If the similarity is greater then a set threshold of 0.6, we replace it in a new utterance\n",
    "\n",
    "                if(similarity > 0.6):\n",
    "                    new_sentence.append(synonym)\n",
    "                else:\n",
    "                    new_sentence.append(token.text)\n",
    "            else:\n",
    "                new_sentence.append(token.text)\n",
    "        else:\n",
    "            new_sentence.append(token.text)\n",
    "\n",
    "    return ' '.join(new_sentence)\n",
    "\n",
    "\n",
    "# Augmenting the DataFrame with our new utterances\n",
    "augmented_data = []\n",
    "for index, row in df_text.iterrows():\n",
    "    augmented_utterance = replace_with_synonyms(row['utterance'])\n",
    "    augmented_data.append({\n",
    "        'utterance': augmented_utterance,\n",
    "        'speaker': row['speaker'],\n",
    "        'context': row['context'],\n",
    "        'context_speakers': row['context_speakers'],\n",
    "        'show': row['show'],\n",
    "        'sarcasm': row['sarcasm']\n",
    "    })\n",
    "\n",
    "# Merging our original data witht he augmented DataFrame\n",
    "augmented_df = pd.DataFrame(augmented_data)\n",
    "\n",
    "combined_df = pd.concat([df_text, augmented_df], ignore_index=True)\n",
    "\n",
    "# Testing how the synonym replacement worked\n",
    "\n",
    "index_to_compare = 4 # Modify here if you want to look at different utterences\n",
    "\n",
    "\n",
    "original_utterance = combined_df.loc[index_to_compare, 'utterance']\n",
    "augmented_utterance = combined_df.loc[len(df_text) + index_to_compare, 'utterance']\n",
    "\n",
    "print(\"Original Utterance:\", original_utterance)\n",
    "print(\"Augmented Utterance:\", augmented_utterance)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1266\n"
     ]
    }
   ],
   "source": [
    "combined_df.head()\n",
    "print(len(combined_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1242\n"
     ]
    }
   ],
   "source": [
    "combined_df.drop_duplicates(subset=['utterance'], inplace=True)\n",
    "print(len(combined_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df.to_csv('enriched_utterances.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DL",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\celin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import nltk\n",
    "nltk.download('wordnet')\n",
    "from nltk.corpus import wordnet\n",
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "import random\n",
    "from torch.utils.data import random_split\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the sarcasm data textual representation\n",
    "file_path = \"data/sarcasm_data.json\"\n",
    "\n",
    "# Loading JSON file\n",
    "with open(file_path) as f:\n",
    "    data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1_60 {'utterance': \"It's just a privilege to watch your mind at work.\", 'speaker': 'SHELDON', 'context': ['I never would have identified the fingerprints of string theory in the aftermath of the Big Bang.', \"My apologies. What's your plan?\"], 'context_speakers': ['LEONARD', 'SHELDON'], 'show': 'BBT', 'sarcasm': True}\n"
     ]
    }
   ],
   "source": [
    "# Look at the data\n",
    "for key, value in data.items():\n",
    "    print(key, value)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For our project it is essential for us to be able to label the different utterances by gender (of the speaker). Therefore we will remove all entries spoken by an ambiguous gender (such as 'Person1' or 'Moderator'). We remarked that this will remove 57 utternaces, which we deem acceptable for the size of our dataset.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter out entries where speaker gender is unclear\n",
    "filtered_data = {key: entry for key, entry in data.items() if entry['speaker'] not in ['PERSON', 'PERSON1', 'PERSON3', 'MODERATOR']}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then assign gender labels to each speaker, and thus each utterance. This was done by hand as there were only 17 different speakers in our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GENDER LABELING\n",
    "# Creating a dictionnary to label the different speakers according to their gender\n",
    "gender_mapping = {\n",
    "    'SHELDON': 'M',\n",
    "    'PENNY': 'F',\n",
    "    'HOWARD': 'M',\n",
    "    'LEONARD': 'M',\n",
    "    'RAJ': 'M',\n",
    "    'BERNADETTE': 'F',\n",
    "    'AMY': 'F',\n",
    "    'CHANDLER': 'M',\n",
    "    'ROSS': 'M',\n",
    "    'MONICA': 'F',\n",
    "    'JOEY': 'M',\n",
    "    'RACHEL': 'F',\n",
    "    'PHOEBE': 'F',\n",
    "    'DOROTHY': 'F',\n",
    "    'ROSE': 'F',\n",
    "    'MEMBER-GIRL': 'F',\n",
    "    'MEMBER-BOY': 'M',\n",
    "}\n",
    "\n",
    "# Define a function to map speakers to their corresponding gender\n",
    "def map_gender(speaker):\n",
    "    return gender_mapping.get(speaker, 'Unknown')\n",
    "\n",
    "# Iterate through the items in the JSON object and add a new key 'gender' for each entry\n",
    "for key, entry in filtered_data.items():\n",
    "    entry['gender'] = map_gender(entry['speaker'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter data by gender\n",
    "F_data = {key: entry for key, entry in filtered_data.items() if entry['gender'] == 'F'}\n",
    "M_data = {key: entry for key, entry in filtered_data.items() if entry['gender'] == 'M'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of utterances by men: 430\n",
      "Number of utterances by women: 203\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of utterances by men:\", len(M_data))\n",
    "print(\"Number of utterances by women:\", len(F_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save gender-split  and cleaned data to json files\n",
    "with open('data/F_data.json', 'w') as f:\n",
    "    json.dump(F_data, f, indent=4)\n",
    "\n",
    "with open('data/M_data.json', 'w') as f:\n",
    "    json.dump(M_data, f, indent=4)\n",
    "\n",
    "with open('data/mixed_data.json', 'w') as f:\n",
    "    json.dump(filtered_data, f, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this project we will build 3 different models:\n",
    "- mixed model (trained on male + female)\n",
    "- male model\n",
    "- female model\n",
    "\n",
    "In order for the models to be unbiased, the training datasets have to be balanced, i.e. there should be the same number of sarcastic and non-sarcastic utterances.\n",
    "\n",
    "In addition, to not be biased towards one gender, the mixed dataset should also be balanced accoring to gender.\n",
    "\n",
    "Let's check if this is the case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking label balance within the different datasets:\n",
      "The original dataset is balanced\n",
      "Sarcastic utterances: 326\n",
      "Non sarcastic utterances: 307\n",
      "Male sarcastic utterances: 224\n",
      "Male non sarcastic utterances: 206\n",
      "Female sarcastic utterances: 102\n",
      "Female non sarcastic utterances: 101\n",
      "\n",
      "Checking gender balance of the filtered dataset:\n",
      "Male utterances: 430\n",
      "Female utterances: 203\n"
     ]
    }
   ],
   "source": [
    "# Checking if the datasets are balanced\n",
    "print('Checking label balance within the different datasets:')\n",
    "if len([(key, value) for key, value in data.items() if value['sarcasm']]) == len([(key, value) for key, value in data.items() if not value['sarcasm']]):\n",
    "    print('The original dataset is balanced')\n",
    "\n",
    "n_sarcastic_utterances = len([(key, value) for key, value in filtered_data.items() if value['sarcasm']])\n",
    "n_non_sarcastic_utterances = len([(key, value) for key, value in filtered_data.items() if not value['sarcasm']])\n",
    "if n_sarcastic_utterances == n_non_sarcastic_utterances:\n",
    "    print('The filtered dataset is balanced')\n",
    "else:\n",
    "    print('Sarcastic utterances:', n_sarcastic_utterances)\n",
    "    print('Non sarcastic utterances:', n_non_sarcastic_utterances)\n",
    "\n",
    "M_n_sarcastic_utterances = len([(key, value) for key, value in M_data.items() if value['sarcasm']])\n",
    "M_n_non_sarcastic_utterances = len([(key, value) for key, value in M_data.items() if not value['sarcasm']])\n",
    "if M_n_sarcastic_utterances == M_n_non_sarcastic_utterances:\n",
    "    print('The male dataset is balanced')\n",
    "else:\n",
    "    print('Male sarcastic utterances:', M_n_sarcastic_utterances)\n",
    "    print('Male non sarcastic utterances:', M_n_non_sarcastic_utterances)\n",
    "\n",
    "F_n_sarcastic_utterances = len([(key, value) for key, value in F_data.items() if value['sarcasm']])\n",
    "F_n_non_sarcastic_utterances = len([(key, value) for key, value in F_data.items() if not value['sarcasm']])\n",
    "if F_n_sarcastic_utterances == F_n_non_sarcastic_utterances:\n",
    "    print('The female dataset is balanced')\n",
    "else:\n",
    "    print('Female sarcastic utterances:', F_n_sarcastic_utterances)\n",
    "    print('Female non sarcastic utterances:', F_n_non_sarcastic_utterances)\n",
    "\n",
    "print(\"\")\n",
    "\n",
    "# Checking if the mixed dataset is balanced by gender\n",
    "n_male_utterances = len([(key, value) for key, value in filtered_data.items() if value['gender'] == 'M'])\n",
    "n_female_utterances = len([(key, value) for key, value in filtered_data.items() if value['gender'] == 'F'])\n",
    "if n_male_utterances == n_female_utterances:\n",
    "    print('The original dataset is balanced by gender')\n",
    "else:\n",
    "    print('Checking gender balance of the filtered dataset:')\n",
    "    print('Male utterances:', n_male_utterances)\n",
    "    print('Female utterances:', n_female_utterances)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see the mixed dataset is not at all balanced by gender, as there are twice as many male utterances as female utterances. It is also not quite balanced in terms of sarcasm labels.\n",
    "\n",
    "The male dataset is also not quite balanced, as there are a few more sarcastic utterances than non-sarcastic utterances.\n",
    "\n",
    "The female dataset can be considered balances, as the difference between sarcastic and non-sarcastic utterances is only 1.\n",
    "\n",
    "To balance the datasets we will use resampling and data augmentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some functions needed for data augmentation\n",
    "INCLUDED_POS_TAGS = {\"VERB\", \"NOUN\", \"ADJ\"}\n",
    "\n",
    "def get_synonyms(word):\n",
    "    synonyms = set()\n",
    "    for synset in wordnet.synsets(word):\n",
    "        for lemma in synset.lemmas():\n",
    "            synonyms.add(lemma.name())\n",
    "    return list(synonyms)\n",
    "\n",
    "def replace_with_synonyms(sentence):\n",
    "    doc = nlp(sentence)\n",
    "    new_sentence = []\n",
    "\n",
    "    for token in doc:\n",
    "        if token.text.isalpha() and not token.is_stop and token.pos_ in INCLUDED_POS_TAGS:\n",
    "            \n",
    "            synonyms = [token.text]  # Starting with the original word\n",
    "            \n",
    "            # Finding synonyms from WordNet\n",
    "            word_synonyms = get_synonyms(token.text)\n",
    "\n",
    "            if word_synonyms and len(word_synonyms) > 1:\n",
    "                \n",
    "                # Selecting the second synonym. The first is often the word itself, whilst later synonyms are further away concerning similarity.\n",
    "                synonym = word_synonyms[1]\n",
    "\n",
    "                word_nlp = nlp(token.text)\n",
    "                synonym_nlp = nlp(synonym)\n",
    "\n",
    "                # Checking the similarity between the original word and the proposed synonym\n",
    "\n",
    "                similarity = word_nlp.similarity(synonym_nlp)\n",
    "\n",
    "                # If the similarity is greater then a set threshold of 0.6, we replace it in a new utterance\n",
    "\n",
    "                if(similarity > 0.6):\n",
    "                    new_sentence.append(synonym)\n",
    "                else:\n",
    "                    new_sentence.append(token.text)\n",
    "            else:\n",
    "                new_sentence.append(token.text)\n",
    "        else:\n",
    "            new_sentence.append(token.text)\n",
    "\n",
    "    return ' '.join(new_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\celin\\AppData\\Local\\Temp\\ipykernel_17444\\3008740719.py:33: UserWarning: [W007] The model you're using has no word vectors loaded, so the result of the Doc.similarity method will be based on the tagger, parser and NER, which may not give useful similarity judgements. This may happen if you're using one of the small models, e.g. `en_core_web_sm`, which don't ship with word vectors and only use context-sensitive tensors. You can always add your own word vectors, or use one of the larger models instead if available.\n",
      "  similarity = word_nlp.similarity(synonym_nlp)\n"
     ]
    }
   ],
   "source": [
    "# DATA AUGMENTATION OF THE MALE DATASET\n",
    "\n",
    "# Load the data from the JSON files\n",
    "with open('data/M_data.json') as file:\n",
    "    M_data = json.load(file)\n",
    "\n",
    "# To balance the dataset 18 non-sarcastic utterances have to be added\n",
    "# These are randomly selected from the non-sarcastic utterances and then augmented\n",
    "non_sarcastic_utterances = [(key, value) for key, value in M_data.items() if not value['sarcasm']]\n",
    "selected_keys = random.sample(non_sarcastic_utterances, k=18)\n",
    "\n",
    "# Data augmentation\n",
    "augmented_data = {}\n",
    "for key, value in selected_keys:\n",
    "    augmented_utterance = replace_with_synonyms(value['utterance'])\n",
    "    augmented_data['A' + key] = {\n",
    "        'utterance': augmented_utterance,\n",
    "        'speaker': value['speaker'],\n",
    "        'context': value['context'],\n",
    "        'context_speakers': value['context_speakers'],\n",
    "        'show': value['show'],\n",
    "        'sarcasm': value['sarcasm'],\n",
    "        'gender' : value['gender']\n",
    "    }\n",
    "\n",
    "# Combining the original data with the augmented data\n",
    "M_combined_data = {**M_data, **augmented_data}\n",
    "\n",
    "# SHOULD WE DROP DUPLICATES?? \n",
    "\n",
    "# Saving the combined data to a JSON file\n",
    "with open('data/M_data_enriched.json', 'w') as f:\n",
    "    json.dump(M_combined_data, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Male sarcastic utterances after augmentation: 224\n",
      "Male non sarcastic utterances after augmentation: 224\n",
      "The male dataset is now balanced\n"
     ]
    }
   ],
   "source": [
    "# Check data augmentation of male dataset\n",
    "n_sarcastic_utterances = len([(key, value) for key, value in M_combined_data.items() if value['sarcasm']])\n",
    "n_non_sarcastic_utterances = len([(key, value) for key, value in M_combined_data.items() if not value['sarcasm']])\n",
    "\n",
    "print('Male sarcastic utterances after augmentation:', n_sarcastic_utterances)\n",
    "print('Male non sarcastic utterances after augmentation:', n_non_sarcastic_utterances)\n",
    "if n_sarcastic_utterances == n_non_sarcastic_utterances:\n",
    "    print('The male dataset is now balanced')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\celin\\AppData\\Local\\Temp\\ipykernel_17444\\3008740719.py:33: UserWarning: [W007] The model you're using has no word vectors loaded, so the result of the Doc.similarity method will be based on the tagger, parser and NER, which may not give useful similarity judgements. This may happen if you're using one of the small models, e.g. `en_core_web_sm`, which don't ship with word vectors and only use context-sensitive tensors. You can always add your own word vectors, or use one of the larger models instead if available.\n",
      "  similarity = word_nlp.similarity(synonym_nlp)\n"
     ]
    }
   ],
   "source": [
    "# DATA AUGMENTATION OF THE MIXED DATASET\n",
    "\n",
    "# Load the data from the JSON files\n",
    "with open('data/mixed_data.json') as file:\n",
    "    mixed_data = json.load(file)\n",
    "\n",
    "# To balance the dataset 227 female utterances have to be added\n",
    "# These are randomly selected from the non-sarcastic utterances and then augmented\n",
    "female_utterances = [(key, value) for key, value in mixed_data.items() if value['gender'] == 'F']\n",
    "selected_keys1 = random.sample(female_utterances, k=len(female_utterances))\n",
    "female_non_sarcastic_utterances = [(key, value) for key, value in mixed_data.items() if value['gender'] == 'F' and not value['sarcasm']]\n",
    "selected_keys2 = random.sample(female_non_sarcastic_utterances, k=24)\n",
    "selected_keys2 = [('a'+ key, value) for key, value in selected_keys2]\n",
    "selected_keys = selected_keys1 + selected_keys2\n",
    "\n",
    "# Data augmentation\n",
    "augmented_data = {}\n",
    "for key, value in selected_keys:\n",
    "    augmented_utterance = replace_with_synonyms(value['utterance'])\n",
    "    augmented_data['A' + key] = {\n",
    "        'utterance': augmented_utterance,\n",
    "        'speaker': value['speaker'],\n",
    "        'context': value['context'],\n",
    "        'context_speakers': value['context_speakers'],\n",
    "        'show': value['show'],\n",
    "        'sarcasm': value['sarcasm'],\n",
    "        'gender' : value['gender']\n",
    "    }\n",
    "\n",
    "# Combining the original data with the augmented data\n",
    "mixed_combined_data = {**mixed_data, **augmented_data}\n",
    "\n",
    "# SHOULD WE DROP DUPLICATES?? \n",
    "\n",
    "# Saving the combined data to a JSON file\n",
    "with open('data/mixed_data_enriched.json', 'w') as f:\n",
    "    json.dump(mixed_combined_data, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Utterances by men in the mixed dataset after augmentation: 430\n",
      "Utterances by women in the mixed dataset after augmentation: 430\n",
      "Sarcastic utterances in the mixed dataset after augmentation: 428\n",
      "Non sarcastic utterances in the mixed dataset after augmentation: 432\n"
     ]
    }
   ],
   "source": [
    "# Check data augmentation of mixed dataset\n",
    "n_female_utterances = len([(key, value) for key, value in mixed_combined_data.items() if value['gender'] == 'F'])\n",
    "n_male_utterances = len([(key, value) for key, value in mixed_combined_data.items() if not value['gender'] == 'F'])\n",
    "n_sarcastic_utterances = len([(key, value) for key, value in mixed_combined_data.items() if value['sarcasm']])\n",
    "n_non_sarcastic_utterances = len([(key, value) for key, value in mixed_combined_data.items() if not value['sarcasm']])\n",
    "\n",
    "print('Utterances by men in the mixed dataset after augmentation:', n_male_utterances)\n",
    "print('Utterances by women in the mixed dataset after augmentation:', n_female_utterances)\n",
    "print('Sarcastic utterances in the mixed dataset after augmentation:', n_sarcastic_utterances)\n",
    "print('Non sarcastic utterances in the mixed dataset after augmentation:', n_non_sarcastic_utterances)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have managed to balance the male dataset using data augmentation, so we will use the augmented dataset for training our models.\n",
    "\n",
    "We have been able to balance the mixed dataset by gender. The balancing by sarcasm is not perfect but can be considered sufficient, relatively to the size of this dataset. We will therefore also use the augmented dataset for training with mixed data.\n",
    "\n",
    "For female data, we can keep using the non-augmented dataset.\n",
    "\n",
    "For training, we will split each dataset into 3 subsets: training, validation, and testing. To make sure that these three subsets are also balanced, we will define them here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mixed dataset: 142 158 156 144\n"
     ]
    }
   ],
   "source": [
    "# Making sure the training, validation and test datasets are also balanced.\n",
    "\n",
    "# Mixed\n",
    "female_sarcastic_utterances = [(key, value) for key, value in mixed_combined_data.items() if value['gender'] == 'F' and value['sarcasm']]\n",
    "female_non_sarcastic_utterances = [(key, value) for key, value in mixed_combined_data.items() if value['gender'] == 'F' and not value['sarcasm']]\n",
    "male_sarcastic_utterances = [(key, value) for key, value in mixed_combined_data.items() if value['gender'] == 'M' and value['sarcasm']]\n",
    "male_non_sarcastic_utterances = [(key, value) for key, value in mixed_combined_data.items() if value['gender'] == 'M' and not value['sarcasm']]\n",
    "\n",
    "train_size = int(0.7 * len(female_sarcastic_utterances))\n",
    "val_size = int(0.15 * len(female_sarcastic_utterances))\n",
    "test_size = len(female_sarcastic_utterances) - train_size - val_size\n",
    "\n",
    "FS_train, FS_test_val = train_test_split(female_sarcastic_utterances, test_size = 0.3)\n",
    "FS_test, FS_val = train_test_split(FS_test_val, test_size = 0.5)\n",
    "\n",
    "train_size = int(0.7 * len(female_non_sarcastic_utterances))\n",
    "val_size = int(0.15 * len(female_non_sarcastic_utterances))\n",
    "test_size = len(female_non_sarcastic_utterances) - train_size - val_size\n",
    "\n",
    "FnS_train, FnS_test_val = train_test_split(female_non_sarcastic_utterances, test_size = 0.3)\n",
    "FnS_test, FnS_val = train_test_split(FnS_test_val, test_size = 0.5)\n",
    "\n",
    "train_size = int(0.7 * len(male_sarcastic_utterances))\n",
    "val_size = int(0.15 * len(male_sarcastic_utterances))\n",
    "test_size = len(male_sarcastic_utterances) - train_size - val_size\n",
    "\n",
    "MS_train, MS_test_val = train_test_split(male_sarcastic_utterances, test_size = 0.3)\n",
    "MS_test, MS_val = train_test_split(MS_test_val, test_size = 0.5)\n",
    "\n",
    "train_size = int(0.7 * len(male_non_sarcastic_utterances))\n",
    "val_size = int(0.15 * len(male_non_sarcastic_utterances))\n",
    "test_size = len(male_non_sarcastic_utterances) - train_size - val_size\n",
    "\n",
    "MnS_train, MnS_test_val = train_test_split(male_non_sarcastic_utterances, test_size = 0.3)\n",
    "MnS_test, MnS_val = train_test_split(MnS_test_val, test_size = 0.5)\n",
    "\n",
    "train_set_mixed = dict(FS_train + FnS_train + MS_train + MnS_train)\n",
    "val_set_mixed = dict(FS_val + FnS_val + MS_val + MnS_val)\n",
    "test_set_mixed =  dict(FS_test + FnS_test + MS_test + MnS_test)\n",
    "\n",
    "print(\"Mixed dataset:\", len(FS_train), len(FnS_train), len(MS_train), len(MnS_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Male\n",
    "M_sarcastic_utterances = [(key, value) for key, value in M_combined_data.items() if value['gender'] == 'M' and value['sarcasm']]\n",
    "M_non_sarcastic_utterances = [(key, value) for key, value in M_combined_data.items() if value['gender'] == 'M' and not value['sarcasm']]\n",
    "\n",
    "train_size = int(0.8 * len(M_sarcastic_utterances))\n",
    "val_size = int(0.1 * len(M_sarcastic_utterances))\n",
    "test_size = len(M_sarcastic_utterances) - train_size - val_size\n",
    "\n",
    "MS_train, MS_test_val = train_test_split(M_sarcastic_utterances, test_size = 0.2)\n",
    "MS_test, MS_val = train_test_split(MS_test_val, test_size = 0.5)\n",
    "\n",
    "train_size = int(0.8 * len(M_non_sarcastic_utterances))\n",
    "val_size = int(0.1 * len(M_non_sarcastic_utterances))\n",
    "test_size = len(M_non_sarcastic_utterances) - train_size - val_size\n",
    "\n",
    "MnS_train, MnS_test_val = train_test_split(M_non_sarcastic_utterances, test_size = 0.2)\n",
    "MnS_test, MnS_val = train_test_split(MnS_test_val, test_size = 0.5)\n",
    "\n",
    "train_set_M = dict(MS_train + MnS_train)\n",
    "val_set_M = dict(MS_val + MnS_val)\n",
    "test_set_M = dict(MS_test + MnS_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Female\n",
    "F_sarcastic_utterances = [(key, value) for key, value in F_data.items() if value['gender'] == 'F' and value['sarcasm']]\n",
    "F_non_sarcastic_utterances = [(key, value) for key, value in F_data.items() if value['gender'] == 'F' and not value['sarcasm']]\n",
    "\n",
    "train_size = int(0.8 * len(F_sarcastic_utterances))\n",
    "val_size = int(0.1 * len(F_sarcastic_utterances))\n",
    "test_size = len(F_sarcastic_utterances) - train_size - val_size\n",
    "\n",
    "FS_train, FS_test_val = train_test_split(F_sarcastic_utterances, test_size = 0.2)\n",
    "FS_test, FS_val = train_test_split(FS_test_val, test_size = 0.5)\n",
    "\n",
    "train_size = int(0.8 * len(F_non_sarcastic_utterances))\n",
    "val_size = int(0.1 * len(F_non_sarcastic_utterances))\n",
    "test_size = len(F_non_sarcastic_utterances) - train_size - val_size\n",
    "\n",
    "FnS_train, FnS_test_val = train_test_split(F_non_sarcastic_utterances, test_size = 0.2)\n",
    "FnS_test, FnS_val = train_test_split(FnS_test_val, test_size = 0.5)\n",
    "\n",
    "train_set_F = dict(FS_train + FnS_train)\n",
    "val_set_F = dict(FS_val + FnS_val)\n",
    "test_set_F = dict(FS_test + FnS_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save subsets as JSON files to be used in training\n",
    "with open('data/mixed_train_set.json', 'w') as f:\n",
    "    json.dump(train_set_mixed, f, indent=4)\n",
    "\n",
    "with open('data/mixed_val_set.json', 'w') as f:\n",
    "    json.dump(val_set_mixed, f, indent=4)\n",
    "\n",
    "with open('data/mixed_test_set.json', 'w') as f:\n",
    "    json.dump(test_set_mixed, f, indent=4)\n",
    "\n",
    "with open('data/M_train_set.json', 'w') as f:\n",
    "    json.dump(train_set_M, f, indent=4)\n",
    "\n",
    "with open('data/M_val_set.json', 'w') as f:\n",
    "    json.dump(val_set_M, f, indent=4)\n",
    "\n",
    "with open('data/M_test_set.json', 'w') as f:\n",
    "    json.dump(test_set_M, f, indent=4)\n",
    "\n",
    "with open('data/F_train_set_alternative.json', 'w') as f:\n",
    "    json.dump(train_set_F, f, indent=4)\n",
    "\n",
    "with open('data/F_val_set_alternative.json', 'w') as f:\n",
    "    json.dump(val_set_F, f, indent=4)\n",
    "\n",
    "with open('data/F_test_set_alternative.json', 'w') as f:\n",
    "    json.dump(test_set_F, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Let's check the size of the different datasets: \n",
      "Mixed data total 860\n",
      "Mixed train 600\n",
      "Mixed val 130\n",
      "Mixed test 130\n",
      "\n",
      "M data total 448\n",
      "M train 312\n",
      "M val 68\n",
      "M test 68\n",
      "\n",
      "F data total 203\n",
      "F train 141\n",
      "F val 32\n",
      "F test 30\n"
     ]
    }
   ],
   "source": [
    "print(\"Let's check the size of the different datasets: \")\n",
    "\n",
    "print(\"Mixed data total\", len(mixed_combined_data))\n",
    "print(\"Mixed train\", len(train_set_mixed))\n",
    "print(\"Mixed val\", len(val_set_mixed))\n",
    "print(\"Mixed test\", len(test_set_mixed))\n",
    "\n",
    "print(\"\")\n",
    "print(\"M data total\", len(M_combined_data))\n",
    "print(\"M train\", len(train_set_M))\n",
    "print(\"M val\", len(val_set_M))\n",
    "print(\"M test\", len(test_set_M))\n",
    "\n",
    "print(\"\")\n",
    "print(\"F data total\", len(F_data))\n",
    "print(\"F train\", len(train_set_F))\n",
    "print(\"F val\", len(val_set_F))\n",
    "print(\"F test\", len(test_set_F))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking label balance within the different datasets:\n",
      "The mixed training dataset is NOT balanced\n",
      "mixed train - sarcastic utterances: 298\n",
      "mixed train - non sarcastic utterances: 302\n",
      "The mixed testing dataset is balanced\n",
      "The mixed validation dataset is balanced\n",
      "\n",
      "The male training dataset is balanced\n",
      "The male testing dataset is balanced\n",
      "The male validation dataset is balanced\n",
      "\n",
      "The female training dataset is NOT balanced\n",
      "female train - sarcastic utterances: 71\n",
      "female train - non sarcastic utterances: 70\n",
      "The female testing dataset is balanced\n",
      "The female validation dataset is balanced\n",
      "\n",
      "The mixed training dataset is balanced by gender\n",
      "The mixed testing dataset is balanced by gender\n",
      "The mixed training dataset is balanced by gender\n"
     ]
    }
   ],
   "source": [
    "# Checking if the datasets are balanced\n",
    "print('Checking label balance within the different datasets:')\n",
    "if len([(key, value) for key, value in test_set_mixed.items() if value['sarcasm']]) == len([(key, value) for key, value in train_set_mixed.items() if not value['sarcasm']]):\n",
    "    print('The mixed training dataset is balanced')\n",
    "else:\n",
    "    print('The mixed training dataset is NOT balanced')\n",
    "    print('mixed train - sarcastic utterances:', len([(key, value) for key, value in train_set_mixed.items() if value['sarcasm']]))\n",
    "    print('mixed train - non sarcastic utterances:', len([(key, value) for key, value in train_set_mixed.items() if not value['sarcasm']]))\n",
    "\n",
    "n_sarcastic_utterances = len([(key, value) for key, value in test_set_mixed.items() if value['sarcasm']])\n",
    "n_non_sarcastic_utterances = len([(key, value) for key, value in test_set_mixed.items() if not value['sarcasm']])\n",
    "if n_sarcastic_utterances == n_non_sarcastic_utterances:\n",
    "    print('The mixed testing dataset is balanced')\n",
    "\n",
    "n_sarcastic_utterances = len([(key, value) for key, value in val_set_mixed.items() if value['sarcasm']])\n",
    "n_non_sarcastic_utterances = len([(key, value) for key, value in val_set_mixed.items() if not value['sarcasm']])\n",
    "if n_sarcastic_utterances == n_non_sarcastic_utterances:\n",
    "    print('The mixed validation dataset is balanced')\n",
    "\n",
    "\n",
    "print(\"\")\n",
    "\n",
    "M_n_sarcastic_utterances = len([(key, value) for key, value in train_set_M.items() if value['sarcasm']])\n",
    "M_n_non_sarcastic_utterances = len([(key, value) for key, value in train_set_M.items() if not value['sarcasm']])\n",
    "if M_n_sarcastic_utterances == M_n_non_sarcastic_utterances:\n",
    "    print('The male training dataset is balanced')\n",
    "\n",
    "M_n_sarcastic_utterances = len([(key, value) for key, value in test_set_M.items() if value['sarcasm']])\n",
    "M_n_non_sarcastic_utterances = len([(key, value) for key, value in test_set_M.items() if not value['sarcasm']])\n",
    "if M_n_sarcastic_utterances == M_n_non_sarcastic_utterances:\n",
    "    print('The male testing dataset is balanced')\n",
    "\n",
    "M_n_sarcastic_utterances = len([(key, value) for key, value in val_set_M.items() if value['sarcasm']])\n",
    "M_n_non_sarcastic_utterances = len([(key, value) for key, value in val_set_M.items() if not value['sarcasm']])\n",
    "if M_n_sarcastic_utterances == M_n_non_sarcastic_utterances:\n",
    "    print('The male validation dataset is balanced')\n",
    "\n",
    "\n",
    "print(\"\")\n",
    "\n",
    "F_n_sarcastic_utterances = len([(key, value) for key, value in train_set_F.items() if value['sarcasm']])\n",
    "F_n_non_sarcastic_utterances = len([(key, value) for key, value in train_set_F.items() if not value['sarcasm']])\n",
    "if F_n_sarcastic_utterances == F_n_non_sarcastic_utterances:\n",
    "    print('The female training dataset is balanced')\n",
    "else:\n",
    "    print('The female training dataset is NOT balanced')\n",
    "    print('female train - sarcastic utterances:', F_n_sarcastic_utterances)\n",
    "    print('female train - non sarcastic utterances:', F_n_non_sarcastic_utterances)\n",
    "\n",
    "F_n_sarcastic_utterances = len([(key, value) for key, value in test_set_F.items() if value['sarcasm']])\n",
    "F_n_non_sarcastic_utterances = len([(key, value) for key, value in test_set_F.items() if not value['sarcasm']])\n",
    "if F_n_sarcastic_utterances == F_n_non_sarcastic_utterances:\n",
    "    print('The female testing dataset is balanced')\n",
    "\n",
    "F_n_sarcastic_utterances = len([(key, value) for key, value in val_set_F.items() if value['sarcasm']])\n",
    "F_n_non_sarcastic_utterances = len([(key, value) for key, value in val_set_F.items() if not value['sarcasm']])\n",
    "if F_n_sarcastic_utterances == F_n_non_sarcastic_utterances:\n",
    "    print('The female validation dataset is balanced')\n",
    "\n",
    "\n",
    "print(\"\")\n",
    "\n",
    "# Checking if the mixed dataset is balanced by gender\n",
    "n_male_utterances = len([(key, value) for key, value in train_set_mixed.items() if value['gender'] == 'M'])\n",
    "n_female_utterances = len([(key, value) for key, value in train_set_mixed.items() if value['gender'] == 'F'])\n",
    "if n_male_utterances == n_female_utterances:\n",
    "    print('The mixed training dataset is balanced by gender')\n",
    "else:\n",
    "    print('Checking gender balance of the filtered dataset:')\n",
    "    print('Male utterances:', n_male_utterances)\n",
    "    print('Female utterances:', n_female_utterances)\n",
    "\n",
    "n_male_utterances = len([(key, value) for key, value in test_set_mixed.items() if value['gender'] == 'M'])\n",
    "n_female_utterances = len([(key, value) for key, value in test_set_mixed.items() if value['gender'] == 'F'])\n",
    "if n_male_utterances == n_female_utterances:\n",
    "    print('The mixed testing dataset is balanced by gender')\n",
    "\n",
    "n_male_utterances = len([(key, value) for key, value in val_set_mixed.items() if value['gender'] == 'M'])\n",
    "n_female_utterances = len([(key, value) for key, value in val_set_mixed.items() if value['gender'] == 'F'])\n",
    "if n_male_utterances == n_female_utterances:\n",
    "    print('The mixed training dataset is balanced by gender')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DLproj",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have created, trained and saved the different models, we will evaluate their performance on the other datasets. Here are the different evaluations we will perform:\n",
    "- performance of mixed_model on the female dataset\n",
    "- performance of mixed_model on the male dataset\n",
    "- performance of F_model on the male dataset\n",
    "- performance of F_model on the mixed dataset\n",
    "- performance of M_model on the female dataset\n",
    "- performance of M_model on the mixed dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\celin\\anaconda3\\envs\\DLproj\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import json\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import BertForSequenceClassification, BertTokenizer\n",
    "import torch.nn as nn\n",
    "import functions_text_model as functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class for the PyTorch sarcasm detection Dataset\n",
    "class SarcasmDataset(Dataset):\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = self.data[idx]\n",
    "        utterance = item['utterance']\n",
    "        sarcasm = int(item['sarcasm'])\n",
    "        input_ids, attention_mask = encode_text(utterance)\n",
    "        return input_ids.flatten(), attention_mask.flatten(), sarcasm\n",
    "\n",
    "\n",
    "# Load the BERT tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)\n",
    "\n",
    "\n",
    "# Function to encode the text\n",
    "def encode_text(text):\n",
    "    encoded_dict = tokenizer.encode_plus(\n",
    "                        text,                      # Input text\n",
    "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
    "                        max_length = 64,           # Pad & truncate all sentences\n",
    "                        truncation = True,\n",
    "                        padding = 'max_length',\n",
    "                        return_attention_mask = True,   # Construct attention masks\n",
    "                        return_tensors = 'pt',     # Return pytorch tensors\n",
    "                   )\n",
    "    return encoded_dict['input_ids'], encoded_dict['attention_mask']\n",
    "\n",
    "# Store the results\n",
    "results = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at prajjwal1/bert-tiny and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at prajjwal1/bert-tiny and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at prajjwal1/bert-tiny and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# Set hyperparameters\n",
    "batch_size = 64\n",
    "dropout_prob = 0\n",
    "\n",
    "\n",
    "# Load the data from the JSON files\n",
    "with open('data/F_data.json') as file:\n",
    "    F_data = json.load(file)\n",
    "\n",
    "with open('data/M_data.json') as file:\n",
    "    M_data = json.load(file)\n",
    "\n",
    "with open('data/mixed_data_enriched.json') as file:\n",
    "    mixed_data = json.load(file)\n",
    "\n",
    "# Convert the data to lists of dictionaries\n",
    "mixed_data = list(mixed_data.values())\n",
    "F_data = list(F_data.values())\n",
    "M_data = list(M_data.values())\n",
    "\n",
    "# Create Pytorch datasets\n",
    "F_dataset = SarcasmDataset(F_data)\n",
    "M_dataset = SarcasmDataset(M_data)\n",
    "mixed_dataset = SarcasmDataset(mixed_data)\n",
    "\n",
    "# Create dataloaders\n",
    "F_dataloader = DataLoader(F_dataset, batch_size, shuffle=True)\n",
    "M_dataloader = DataLoader(M_dataset, batch_size, shuffle=True)\n",
    "mixed_dataloader = DataLoader(mixed_dataset, batch_size, shuffle=True)\n",
    "\n",
    "\n",
    "\n",
    "# Initialize the models\n",
    "device = torch.device(\"cpu\")\n",
    "\n",
    "# Mixed model\n",
    "mixed_model = BertForSequenceClassification.from_pretrained(\n",
    "    \"prajjwal1/bert-tiny\",\n",
    "    num_labels=2,\n",
    "    output_attentions=False,\n",
    "    output_hidden_states=False,\n",
    ")\n",
    "\n",
    "mixed_model.classifier = nn.Sequential(\n",
    "    nn.Dropout(dropout_prob),\n",
    "    nn.Linear(in_features=128, out_features=64, bias=True),\n",
    "    nn.Tanh(),\n",
    "    nn.Linear(in_features=64, out_features=16, bias=True),\n",
    "    nn.Tanh(),\n",
    "    nn.Linear(in_features=16, out_features=2, bias=True)\n",
    "    )\n",
    "\n",
    "# Load the weights\n",
    "state_dict = torch.load(\"models/mixed_model_enriched_text.pth\")\n",
    "mixed_model.load_state_dict(state_dict)\n",
    "\n",
    "mixed_model.eval()\n",
    "mixed_model.to(device)\n",
    "\n",
    "# F model\n",
    "F_model = BertForSequenceClassification.from_pretrained(\n",
    "    \"prajjwal1/bert-tiny\",\n",
    "    num_labels=2,\n",
    "    output_attentions=False,\n",
    "    output_hidden_states=False,\n",
    ")\n",
    "\n",
    "F_model.classifier = nn.Sequential(\n",
    "    nn.Dropout(dropout_prob),\n",
    "    nn.Linear(in_features=128, out_features=64, bias=True),\n",
    "    nn.Tanh(),\n",
    "    nn.Linear(in_features=64, out_features=16, bias=True),\n",
    "    nn.Tanh(),\n",
    "    nn.Linear(in_features=16, out_features=2, bias=True)\n",
    "    )\n",
    "\n",
    "# Load the weights\n",
    "state_dict = torch.load(\"models/F_model_text.pth\")\n",
    "F_model.load_state_dict(state_dict)\n",
    "\n",
    "F_model.eval()\n",
    "F_model.to(device)\n",
    "\n",
    "# M model\n",
    "M_model = BertForSequenceClassification.from_pretrained(\n",
    "    \"prajjwal1/bert-tiny\",\n",
    "    num_labels=2,\n",
    "    output_attentions=False,\n",
    "    output_hidden_states=False,\n",
    ")\n",
    "\n",
    "M_model.classifier = nn.Sequential(\n",
    "    nn.Dropout(dropout_prob),\n",
    "    nn.Linear(in_features=128, out_features=64, bias=True),\n",
    "    nn.Tanh(),\n",
    "    nn.Linear(in_features=64, out_features=16, bias=True),\n",
    "    nn.Tanh(),\n",
    "    nn.Linear(in_features=16, out_features=2, bias=True)\n",
    "    )\n",
    "\n",
    "# Load the weights\n",
    "state_dict = torch.load(\"models/M_model_text.pth\")\n",
    "M_model.load_state_dict(state_dict)\n",
    "\n",
    "M_model.eval()\n",
    "M_model.to(device)\n",
    "\n",
    "# Define the loss criterion\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Define the metrics\n",
    "metrics = {'ACC': functions.acc, 'F1-weighted': functions.f1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00, 22.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval Loss: 0.6555,  ACC: 0.6733, F1-weighted: 0.6524\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# MIXED MODEL ON FEMALE DATASET\n",
    "\n",
    "# Set seed for reproducibility\n",
    "torch.manual_seed(42)\n",
    "\n",
    "# Evaluate the model\n",
    "test_loss, test_metrics = functions.evaluate(mixed_model, criterion, metrics, F_dataloader, device)\n",
    "\n",
    "# Store the results\n",
    "results['Mixed model on Female dataset'] = {'Test loss': test_loss, 'Test metrics': test_metrics}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:00<00:00, 17.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval Loss: 0.4879,  ACC: 0.8158, F1-weighted: 0.8133\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# MIXED MODEL ON MALE DATASET\n",
    "\n",
    "# Set seed for reproducibility\n",
    "torch.manual_seed(42)\n",
    "\n",
    "# Evaluate the model\n",
    "test_loss, test_metrics = functions.evaluate(mixed_model, criterion, metrics, M_dataloader, device)\n",
    "\n",
    "# Store the results\n",
    "results['Mixed model on Male dataset'] = {'Test loss': test_loss, 'Test metrics': test_metrics}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:00<00:00, 16.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval Loss: 0.6879,  ACC: 0.5487, F1-weighted: 0.5296\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# FEMALE MODEL ON MALE DATASET\n",
    "\n",
    "# Set seed for reproducibility\n",
    "torch.manual_seed(42)\n",
    "\n",
    "# Evaluate the model\n",
    "test_loss, test_metrics = functions.evaluate(F_model, criterion, metrics, M_dataloader, device)\n",
    "\n",
    "# Store the results\n",
    "results['Female model on Male dataset'] = {'Test loss': test_loss, 'Test metrics': test_metrics}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:00<00:00, 15.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval Loss: 0.6884,  ACC: 0.5446, F1-weighted: 0.5322\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# FEMALE MODEL ON MIXED DATASET\n",
    "\n",
    "# Set seed for reproducibility\n",
    "torch.manual_seed(42)\n",
    "\n",
    "# Evaluate the model\n",
    "test_loss, test_metrics = functions.evaluate(F_model, criterion, metrics, mixed_dataloader, device)\n",
    "\n",
    "# Store the results\n",
    "results['Female model on Mixed dataset'] = {'Test loss': test_loss, 'Test metrics': test_metrics}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00, 17.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval Loss: 0.6555,  ACC: 0.6733, F1-weighted: 0.6524\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# MALE MODEL ON FEMALE DATASET\n",
    "\n",
    "# Set seed for reproducibility\n",
    "torch.manual_seed(42)\n",
    "\n",
    "# Evaluate the model\n",
    "test_loss, test_metrics = functions.evaluate(M_model, criterion, metrics, F_dataloader, device)\n",
    "\n",
    "# Store the results\n",
    "results['Male model on Female dataset'] = {'Test loss': test_loss, 'Test metrics': test_metrics}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:00<00:00, 17.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval Loss: 0.4842,  ACC: 0.8192, F1-weighted: 0.8172\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# MALE MODEL ON MIXED DATASET\n",
    "\n",
    "# Set seed for reproducibility\n",
    "torch.manual_seed(42)\n",
    "\n",
    "# Evaluate the model\n",
    "test_loss, test_metrics = functions.evaluate(M_model, criterion, metrics, mixed_dataloader, device)\n",
    "\n",
    "# Store the results\n",
    "results['Male model on Mixed dataset'] = {'Test loss': test_loss, 'Test metrics': test_metrics}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the results\n",
    "with open('results/text_model_evaluation.json', 'w') as f:\n",
    "    json.dump(results, f, indent=4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DLproj",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

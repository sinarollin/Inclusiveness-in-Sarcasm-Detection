{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-23 21:24:15.975134: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "from functions_audio_model_tiny import *\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "import numpy as np\n",
    "import os\n",
    "import json\n",
    "import tensorflow as tf\n",
    "import shutil\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import SparseCategoricalCrossentropy\n",
    "from tensorflow.keras.metrics import SparseCategoricalAccuracy, Mean\n",
    "from sklearn.model_selection import ParameterGrid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First steps include proper sorting of the saved embeddings into the training, test and validation sets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For Female sets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "#IDS for training set female\n",
    "file_path = 'data/F_train_set.json'\n",
    "\n",
    "with open(file_path, 'r') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# Extract the IDs\n",
    "ids_train = list(data.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "141\n"
     ]
    }
   ],
   "source": [
    "print(len(ids_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Source and destination directories\n",
    "src_dir = 'data/audio/embeddingsF/'\n",
    "dst_dir = 'data/audio/embeddingsF_sets/F_train_set'\n",
    "\n",
    "\n",
    "for filename in os.listdir(src_dir):\n",
    "    if filename.endswith('.npy'):\n",
    "        # Extract the id from the filename\n",
    "        id = filename.split('_w2V2.')[0]\n",
    "        \n",
    "        if id in ids_train:\n",
    "            source_file = os.path.join(src_dir, filename)\n",
    "            target_file = os.path.join(dst_dir, filename)\n",
    "            \n",
    "            shutil.copy(source_file, target_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "141\n"
     ]
    }
   ],
   "source": [
    "#count that 141 files have been moved to the training set\n",
    "\n",
    "dir_path = 'data/audio/embeddingsF_sets/F_train_set'\n",
    "\n",
    "files = os.listdir(dir_path)\n",
    "\n",
    "print(len(files))\n",
    "assert len(files) == 141\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "#IDS for test set female\n",
    "file_path = 'data/F_test_set.json'\n",
    "\n",
    "with open(file_path, 'r') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# Extract the IDs\n",
    "ids_test = list(data.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ids_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Source and destination directories\n",
    "src_dir = 'data/audio/embeddingsF/'\n",
    "dst_dir = 'data/audio/embeddingsF_sets/F_test_set'\n",
    "\n",
    "\n",
    "for filename in os.listdir(src_dir):\n",
    "    if filename.endswith('.npy'):\n",
    "        # Extract the id from the filename\n",
    "        id = filename.split('_w2V2.')[0]\n",
    "        \n",
    "        if id in ids_test:\n",
    "            source_file = os.path.join(src_dir, filename)\n",
    "            target_file = os.path.join(dst_dir, filename)\n",
    "            \n",
    "            shutil.copy(source_file, target_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30\n"
     ]
    }
   ],
   "source": [
    "#count that 30 files have been moved to the training set\n",
    "\n",
    "dir_path = 'data/audio/embeddingsF_sets/F_test_set'\n",
    "\n",
    "files = os.listdir(dir_path)\n",
    "\n",
    "print(len(files))\n",
    "assert len(files) == 30\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#IDS for validation set female\n",
    "file_path = 'data/F_val_set.json'\n",
    "\n",
    "with open(file_path, 'r') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# Extract the IDs\n",
    "ids_val = list(data.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ids_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Source and destination directories\n",
    "src_dir = 'data/audio/embeddingsF/'\n",
    "dst_dir = 'data/audio/embeddingsF_sets/F_val_set'\n",
    "\n",
    "\n",
    "for filename in os.listdir(src_dir):\n",
    "    if filename.endswith('.npy'):\n",
    "        # Extract the id from the filename\n",
    "        id = filename.split('_w2V2.')[0]\n",
    "        \n",
    "        if id in ids_val:\n",
    "            source_file = os.path.join(src_dir, filename)\n",
    "            target_file = os.path.join(dst_dir, filename)\n",
    "            \n",
    "            shutil.copy(source_file, target_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32\n"
     ]
    }
   ],
   "source": [
    "#count that 32 files have been moved to the training set\n",
    "\n",
    "dir_path = 'data/audio/embeddingsF_sets/F_val_set'\n",
    "\n",
    "files = os.listdir(dir_path)\n",
    "\n",
    "print(len(files))\n",
    "assert len(files) == 32\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Same procedure for the male set, this will however cause more difficulties due to the augmentations performed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "#IDS for training set male\n",
    "file_path = 'data/M_train_set.json'\n",
    "\n",
    "with open(file_path, 'r') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# Extract the IDs\n",
    "ids_train_M = list(data.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "312"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ids_train_M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1_10462', '1_7089', '1_2819', '1_7575', '1_6065', '1_4031', '1_11913', '2_475', '1_2354', '2_541', '2_151', '1_536', '1_1638', '1_11924', '2_287', '1_1180', '1_5627', '2_128', '1_3287', '2_161', '2_124', '1_105', '2_170', '2_120', '2_392', '1_3707', '2_197', '2_373', '2_494', '2_556', '1_11378', '2_596', '2_152', '2_248', '2_523', '2_450', '2_456', '2_583', '2_288', '1_2614', '2_280', '2_247', '2_598', '1_5058', '1_8045', '1_3125', '2_550', '2_370', '1_6428', '2_39', '2_236', '1_6370', '1_7047', '1_6683', '1_7281', '1_1772', '1_1296', '2_114', '2_586', '2_242', '2_532', '1_6426', '2_103', '2_567', '2_258', '1_5964', '1_1478', '2_313', '2_359', '1_6504', '2_457', '2_377', '1_971', '1_6134', '2_174', '2_406', '2_223', '2_204', '2_474', '1_12202', '2_227', '2_449', '1_5617', '2_581', '1_1466', '1_4967', '2_509', '2_372', '1_2778', '2_433', '2_434', '1_6165', '2_115', '2_490', '1_276', '2_43', '1_6648', '2_73', '2_169', '2_511', '2_178', '1_3293', '2_622', '1_8407', '1_4145', '2_617', '1_5699', '1_3545', '2_286', '2_447', '1_6020', '2_374', '2_24', '1_5572', '2_66', '2_260', '1_11055', '1_11177', '1_11901', '2_608', '2_2', '1_213', '1_1798', '2_186', '2_187', '2_109', '2_345', '2_376', '1_7402', '2_623', '2_484', '2_518', '2_3', '2_172', '2_323', '2_294', '2_310', '1_340', '2_104', '2_573', '1_507', '2_487', '2_430', '2_84', '2_113', '1_4760', '2_34', '2_226', '2_369', '2_112', '2_50', '2_283', '2_183', '2_297', '2_485', '1_6472', '2_481', '1_11120', '2_557', '1_8042', '2_270', '2_555', '1_6183', '1_2842', '1_11723', '2_426', '2_552', '2_531', '1_1262', '2_1', '1_8417', '2_218', '1_6534', '1_3177', 'A2_574', '1_9594', '2_547', '1_162', '1_10859', '1_4281', '2_137', '1_5786', '2_119', '2_235', '1_4290', '1_10977', '1_4949', '1_4286', '1_11046', '2_602', '2_441', '1_6860', '1_7938', '2_387', '2_570', '1_9009', '2_176', '2_472', 'A1_7449', '2_540', '2_574', '2_96', '1_1185', '1_1666', '2_564', '1_1678', 'A2_472', '1_410', '2_268', '2_405', '1_3842', '1_7641', '1_7341', '1_9668', '1_6092', '1_3599', '2_49', '1_7593', '1_11529', '2_181', '1_4850', '1_7082', '2_577', '1_6766', '1_5919', '1_3069', 'A1_11609', '2_339', '2_301', '1_467', 'A2_176', '1_10190', '2_225', '1_7442', '1_8505', '2_594', '2_514', 'A1_2216', '2_305', '2_299', '1_1484', '1_10004', '2_595', '1_8078', '2_35', 'A2_514', '1_2830', '1_2575', '2_375', '2_221', 'A1_2575', '2_243', '1_2075', '1_11526', '2_20', 'A2_358', '2_409', '2_562', '2_326', '2_400', '1_10849', '1_1189', '2_194', '2_535', 'A2_422', '2_463', '1_2361', '2_272', '1_3333', '2_371', '1_7186', '1_10810', '2_365', '2_291', '2_203', '1_12320', '2_87', '2_198', '1_8159', '1_2669', '2_353', 'A1_7490', '1_11236', '2_431', '2_78', '1_3840', '1_7449', '2_334', '1_5581', '1_672', '2_191', '1_7487', '2_588', '1_1722', '1_4352', '2_173', 'A2_8', '1_3476', '1_2664', '1_8837', '1_12083', '2_160', '2_166', '2_48', '2_240', '1_430', '2_537', '2_435', '1_11257', '2_553', '1_7894', '1_6211']\n"
     ]
    }
   ],
   "source": [
    "print(ids_train_M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Source and destination directories\n",
    "src_dir = 'data/audio/embeddingsM/'\n",
    "dst_dir = 'data/audio/embeddingsM_sets/M_train_set'\n",
    "\n",
    "\n",
    "for filename in os.listdir(src_dir):\n",
    "    if filename.endswith('w2V2.npy'):\n",
    "        # Extract the id from the filename\n",
    "        id = filename.split('_w2V2.')[0]\n",
    "        \n",
    "        if id in ids_train_M:\n",
    "            source_file = os.path.join(src_dir, filename)\n",
    "            target_file = os.path.join(dst_dir, filename)\n",
    "            \n",
    "            shutil.copy(source_file, target_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[120], line 8\u001b[0m\n\u001b[1;32m      5\u001b[0m files \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mlistdir(dir_path)\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mlen\u001b[39m(files))\n\u001b[0;32m----> 8\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(files) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m312\u001b[39m\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#count that 141 files have been moved to the training set\n",
    "\n",
    "dir_path = 'data/audio/embeddingsM_sets/M_train_set'\n",
    "\n",
    "files = os.listdir(dir_path)\n",
    "\n",
    "print(len(files))\n",
    "assert len(files) == 312\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As augmentation has been done differently, the difference of 12 files is chosen at random from the Augmented Male files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "# Source and destination directories\n",
    "src_dir = 'data/audio/embeddingsM/'\n",
    "dst_dir = 'data/audio/embeddingsM_sets/M_train_set'\n",
    "\n",
    "# Get a list of all files that end with 'w2V2.npy' and their ids are in ids_train_M\n",
    "files = [f for f in os.listdir(src_dir) if f.startswith('A') and f.endswith('w2V2.npy')]\n",
    "\n",
    "# Randomly select 12 files\n",
    "selected_files = random.sample(files, 12)\n",
    "\n",
    "# Copy the selected files to the destination directory\n",
    "for filename in selected_files:\n",
    "    source_file = os.path.join(src_dir, filename)\n",
    "    target_file = os.path.join(dst_dir, filename)\n",
    "    \n",
    "    shutil.copy(source_file, target_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "312\n",
      "['A_2_20_w2V2.npy', 'A_2_387_w2V2.npy', 'A_1_6627_w2V2.npy', 'A_2_326_w2V2.npy', 'A_1_10190_w2V2.npy', 'A_2_208_w2V2.npy', 'A_1_8217_w2V2.npy', 'A_2_49_w2V2.npy', 'A_1_3840_w2V2.npy', 'A_1_3837_w2V2.npy', 'A_1_3333_w2V2.npy', 'A_1_3476_w2V2.npy']\n",
      "12\n"
     ]
    }
   ],
   "source": [
    "#count that 312 files have been moved to the training set\n",
    "\n",
    "dir_path = 'data/audio/embeddingsM_sets/M_train_set'\n",
    "\n",
    "files = os.listdir(dir_path)\n",
    "\n",
    "print(len(files))\n",
    "assert len(files) == 312\n",
    "# Print the files that start with 'A'\n",
    "files_starting_with_A = [f for f in files if f.startswith('A')]\n",
    "\n",
    "print(files_starting_with_A)\n",
    "print(len(files_starting_with_A))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "#IDS for training set male\n",
    "file_path = 'data/M_test_set.json'\n",
    "\n",
    "with open(file_path, 'r') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# Extract the IDs\n",
    "ids_test_M = list(data.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "68"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ids_test_M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Source and destination directories\n",
    "src_dir = 'data/audio/embeddingsM/'\n",
    "dst_dir = 'data/audio/embeddingsM_sets/M_test_set'\n",
    "\n",
    "\n",
    "for filename in os.listdir(src_dir):\n",
    "    if filename.endswith('w2V2.npy'):\n",
    "        # Extract the id from the filename\n",
    "        id = filename.split('_w2V2.')[0]\n",
    "        \n",
    "        if id in ids_test_M:\n",
    "            source_file = os.path.join(src_dir, filename)\n",
    "            target_file = os.path.join(dst_dir, filename)\n",
    "            \n",
    "            shutil.copy(source_file, target_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#count that 68 files have been moved to the training set\n",
    "\n",
    "dir_path = 'data/audio/embeddingsM_sets/M_test_set'\n",
    "\n",
    "files = os.listdir(dir_path)\n",
    "\n",
    "print(len(files))\n",
    "assert len(files) == 68\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Source and destination directories\n",
    "src_dir = 'data/audio/embeddingsM/'\n",
    "dst_dir = 'data/audio/embeddingsM_sets/M_test_set'\n",
    "train_dir = 'data/audio/embeddingsM_sets/M_train_set'\n",
    "\n",
    "# Get a list of all files that end with 'w2V2.npy' and their ids start with A and are not the same as the ones in the training set\n",
    "files = [f for f in os.listdir(src_dir) if f.startswith('A') and f.endswith('w2V2.npy') and not os.path.exists(os.path.join(train_dir, f))]\n",
    "\n",
    "\n",
    "# Randomly select 2 files\n",
    "selected_files = random.sample(files, 2)\n",
    "\n",
    "# Copy the selected files to the destination directory\n",
    "for filename in selected_files:\n",
    "    source_file = os.path.join(src_dir, filename)\n",
    "    target_file = os.path.join(dst_dir, filename)\n",
    "    \n",
    "    shutil.copy(source_file, target_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "68\n"
     ]
    }
   ],
   "source": [
    "#count that 68 files have been moved to the test set\n",
    "\n",
    "dir_path = 'data/audio/embeddingsM_sets/M_test_set'\n",
    "\n",
    "files = os.listdir(dir_path)\n",
    "\n",
    "print(len(files))\n",
    "assert len(files) == 68\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "#IDS for validation set male\n",
    "file_path = 'data/M_val_set.json'\n",
    "\n",
    "with open(file_path, 'r') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# Extract the IDs\n",
    "ids_val_M = list(data.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "68"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ids_val_M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1_1560', '1_9971', '1_2797', '2_421', '1_5679', '1_1549', '2_189', '1_1003', '2_546', '1_10829', '1_182', '2_71', '2_478', '2_168', '2_206', '2_524', '2_155', '1_7357', '1_2580', '2_498', '1_5571', '1_11699', '2_461', '1_3064', '2_141', '1_10890', '2_464', '1_9087', '2_589', '2_148', '2_416', '1_2853', '2_491', '1_1144', 'A2_49', '1_11306', '1_2216', 'A2_261', '2_127', '2_585', '1_6113', '2_343', '2_446', '2_231', '1_1001', '2_30', '1_80', '2_536', '2_322', '2_208', '2_131', '1_7661', '1_10857', '2_86', '1_2420', '1_4792', '1_2837', '2_397', '1_5953', '2_230', '2_388', '1_6627', '2_488', '1_7490', '1_9245', 'A1_2830', '2_125', 'A1_10004']\n"
     ]
    }
   ],
   "source": [
    "print(ids_val_M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Source and destination directories\n",
    "src_dir = 'data/audio/embeddingsM/'\n",
    "dst_dir = 'data/audio/embeddingsM_sets/M_val_set'\n",
    "\n",
    "\n",
    "for filename in os.listdir(src_dir):\n",
    "    if filename.endswith('w2V2.npy'):\n",
    "        # Extract the id from the filename\n",
    "        id = filename.split('_w2V2.')[0]\n",
    "        \n",
    "        if id in ids_val_M:\n",
    "            source_file = os.path.join(src_dir, filename)\n",
    "            target_file = os.path.join(dst_dir, filename)\n",
    "            \n",
    "            shutil.copy(source_file, target_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[150], line 8\u001b[0m\n\u001b[1;32m      5\u001b[0m files \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mlistdir(dir_path)\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mlen\u001b[39m(files))\n\u001b[0;32m----> 8\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(files) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m68\u001b[39m\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#count that 68 files have been moved to the validation set\n",
    "\n",
    "dir_path = 'data/audio/embeddingsM_sets/M_val_set'\n",
    "\n",
    "files = os.listdir(dir_path)\n",
    "\n",
    "print(len(files))\n",
    "assert len(files) == 68\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Source and destination directories\n",
    "src_dir = 'data/audio/embeddingsM/'\n",
    "dst_dir = 'data/audio/embeddingsM_sets/M_val_set'\n",
    "train_dir = 'data/audio/embeddingsM_sets/M_train_set'\n",
    "test_dir = 'data/audio/embeddingsM_sets/M_test_set'\n",
    "\n",
    "# Get a list of all files that end with 'w2V2.npy' and their ids start with A and are not the same as the ones in the training set\n",
    "files = [f for f in os.listdir(src_dir) if f.startswith('A') and f.endswith('w2V2.npy') \n",
    "         and not os.path.exists(os.path.join(train_dir, f)) and not os.path.exists(os.path.join(test_dir, f))]\n",
    "\n",
    "\n",
    "# Randomly select 4 files\n",
    "selected_files = random.sample(files, 4)\n",
    "\n",
    "# Copy the selected files to the destination directory\n",
    "for filename in selected_files:\n",
    "    source_file = os.path.join(src_dir, filename)\n",
    "    target_file = os.path.join(dst_dir, filename)\n",
    "    \n",
    "    shutil.copy(source_file, target_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "68\n"
     ]
    }
   ],
   "source": [
    "#count that 68 files have been moved to the validation set\n",
    "\n",
    "dir_path = 'data/audio/embeddingsM_sets/M_val_set'\n",
    "\n",
    "files = os.listdir(dir_path)\n",
    "\n",
    "print(len(files))\n",
    "assert len(files) == 68\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Moving on to the mixed datasets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "#IDS for training set mixed\n",
    "file_path = 'data/mixed_train_set.json'\n",
    "\n",
    "with open(file_path, 'r') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# Extract the IDs\n",
    "ids_train_mixed = list(data.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "600"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ids_train_mixed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Source and destination directories\n",
    "src_dir = 'data/audio/embeddingsmixed/'\n",
    "dst_dir = 'data/audio/embeddingsmixed_sets/mixed_train_set'\n",
    "\n",
    "\n",
    "for filename in os.listdir(src_dir):\n",
    "    if filename.endswith('w2V2.npy'):\n",
    "        # Extract the id from the filename\n",
    "        id = filename.split('_w2V2.')[0]\n",
    "        \n",
    "        if id in ids_train_mixed:\n",
    "            source_file = os.path.join(src_dir, filename)\n",
    "            target_file = os.path.join(dst_dir, filename)\n",
    "            \n",
    "            shutil.copy(source_file, target_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "440\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[160], line 8\u001b[0m\n\u001b[1;32m      5\u001b[0m files \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mlistdir(dir_path)\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mlen\u001b[39m(files))\n\u001b[0;32m----> 8\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(files) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m600\u001b[39m\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#count that 68 files have been moved to the validation set\n",
    "\n",
    "dir_path = 'data/audio/embeddingsmixed_sets/mixed_train_set'\n",
    "\n",
    "files = os.listdir(dir_path)\n",
    "\n",
    "print(len(files))\n",
    "assert len(files) == 600\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Source and destination directories\n",
    "src_dir = 'data/audio/embeddingsmixed/'\n",
    "dst_dir = 'data/audio/embeddingsmixed_sets/mixed_train_set'\n",
    "\n",
    "# Get a list of all files that end with 'w2V2.npy' and their ids start with A and are not the same as the ones in the training set\n",
    "files = [f for f in os.listdir(src_dir) if (f.startswith('A1') or f.startswith('A2')) and f.endswith('w2V2.npy')]\n",
    "\n",
    "# Randomly select 160 files\n",
    "selected_files = random.sample(files, 160)\n",
    "\n",
    "# Copy the selected files to the destination directory\n",
    "for filename in selected_files:\n",
    "    source_file = os.path.join(src_dir, filename)\n",
    "    target_file = os.path.join(dst_dir, filename)\n",
    "    \n",
    "    shutil.copy(source_file, target_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600\n"
     ]
    }
   ],
   "source": [
    "#count that 600 files have been moved to the validation set\n",
    "\n",
    "dir_path = 'data/audio/embeddingsmixed_sets/mixed_train_set'\n",
    "\n",
    "files = os.listdir(dir_path)\n",
    "\n",
    "print(len(files))\n",
    "assert len(files) == 600\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "#IDS for training set mixed\n",
    "file_path = 'data/mixed_test_set.json'\n",
    "\n",
    "with open(file_path, 'r') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# Extract the IDs\n",
    "ids_test_mixed = list(data.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "130"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ids_test_mixed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Source and destination directories\n",
    "src_dir = 'data/audio/embeddingsmixed/'\n",
    "dst_dir = 'data/audio/embeddingsmixed_sets/mixed_test_set'\n",
    "\n",
    "\n",
    "for filename in os.listdir(src_dir):\n",
    "    if filename.endswith('w2V2.npy'):\n",
    "        # Extract the id from the filename\n",
    "        id = filename.split('_w2V2.')[0]\n",
    "        \n",
    "        if id in ids_test_mixed:\n",
    "            source_file = os.path.join(src_dir, filename)\n",
    "            target_file = os.path.join(dst_dir, filename)\n",
    "            \n",
    "            shutil.copy(source_file, target_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "98\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[167], line 8\u001b[0m\n\u001b[1;32m      5\u001b[0m files \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mlistdir(dir_path)\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mlen\u001b[39m(files))\n\u001b[0;32m----> 8\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(files) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m130\u001b[39m\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#count that 130 files have been moved to the validation set\n",
    "\n",
    "dir_path = 'data/audio/embeddingsmixed_sets/mixed_test_set'\n",
    "\n",
    "files = os.listdir(dir_path)\n",
    "\n",
    "print(len(files))\n",
    "assert len(files) == 130\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Source and destination directories\n",
    "src_dir = 'data/audio/embeddingsmixed/'\n",
    "dst_dir = 'data/audio/embeddingsmixed_sets/mixed_test_set'\n",
    "train_dir = 'data/audio/embeddingsmixed_sets/mixed_train_set'\n",
    "\n",
    "# Get a list of all files that end with 'w2V2.npy' and their ids start with A and are not the same as the ones in the training set\n",
    "files = [f for f in os.listdir(src_dir) if (f.startswith('A1') or f.startswith('A2')) and f.endswith('w2V2.npy')\n",
    "         and not os.path.exists(os.path.join(train_dir, f))]\n",
    "\n",
    "# Randomly select 32 files\n",
    "selected_files = random.sample(files, 32)\n",
    "\n",
    "# Copy the selected files to the destination directory\n",
    "for filename in selected_files:\n",
    "    source_file = os.path.join(src_dir, filename)\n",
    "    target_file = os.path.join(dst_dir, filename)\n",
    "    \n",
    "    shutil.copy(source_file, target_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130\n"
     ]
    }
   ],
   "source": [
    "#count that 130 files have been moved to the validation set\n",
    "\n",
    "dir_path = 'data/audio/embeddingsmixed_sets/mixed_test_set'\n",
    "\n",
    "files = os.listdir(dir_path)\n",
    "\n",
    "print(len(files))\n",
    "assert len(files) == 130\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "#IDS for validation set mixed\n",
    "file_path = 'data/mixed_val_set.json'\n",
    "\n",
    "with open(file_path, 'r') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# Extract the IDs\n",
    "ids_val_mixed = list(data.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "130"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ids_val_mixed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Source and destination directories\n",
    "src_dir = 'data/audio/embeddingsmixed/'\n",
    "dst_dir = 'data/audio/embeddingsmixed_sets/mixed_val_set'\n",
    "\n",
    "\n",
    "for filename in os.listdir(src_dir):\n",
    "    if filename.endswith('w2V2.npy'):\n",
    "        # Extract the id from the filename\n",
    "        id = filename.split('_w2V2.')[0]\n",
    "        \n",
    "        if id in ids_val_mixed:\n",
    "            source_file = os.path.join(src_dir, filename)\n",
    "            target_file = os.path.join(dst_dir, filename)\n",
    "            \n",
    "            shutil.copy(source_file, target_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[175], line 8\u001b[0m\n\u001b[1;32m      5\u001b[0m files \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mlistdir(dir_path)\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mlen\u001b[39m(files))\n\u001b[0;32m----> 8\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(files) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m130\u001b[39m\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#count that 130 files have been moved to the validation set\n",
    "\n",
    "dir_path = 'data/audio/embeddingsmixed_sets/mixed_val_set'\n",
    "\n",
    "files = os.listdir(dir_path)\n",
    "\n",
    "print(len(files))\n",
    "assert len(files) == 130\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Source and destination directories\n",
    "src_dir = 'data/audio/embeddingsmixed/'\n",
    "dst_dir = 'data/audio/embeddingsmixed_sets/mixed_val_set'\n",
    "train_dir = 'data/audio/embeddingsmixed_sets/mixed_train_set'\n",
    "test_dir = 'data/audio/embeddingsmixed_sets/mixed_test_set'\n",
    "\n",
    "# Get a list of all files that end with 'w2V2.npy' and their ids start with A and are not the same as the ones in the training set\n",
    "files = [f for f in os.listdir(src_dir) if (f.startswith('A1') or f.startswith('A2')) and f.endswith('w2V2.npy')\n",
    "         and not os.path.exists(os.path.join(train_dir, f)) and not os.path.exists(os.path.join(test_dir, f))]\n",
    "\n",
    "\n",
    "# Randomly select 35 files\n",
    "selected_files = random.sample(files, 35)\n",
    "\n",
    "# Copy the selected files to the destination directory\n",
    "for filename in selected_files:\n",
    "    source_file = os.path.join(src_dir, filename)\n",
    "    target_file = os.path.join(dst_dir, filename)\n",
    "    \n",
    "    shutil.copy(source_file, target_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130\n"
     ]
    }
   ],
   "source": [
    "#count that 130 files have been moved to the validation set\n",
    "\n",
    "dir_path = 'data/audio/embeddingsmixed_sets/mixed_val_set'\n",
    "\n",
    "files = os.listdir(dir_path)\n",
    "\n",
    "print(len(files))\n",
    "assert len(files) == 130\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now to the creation of the correct labels for the correct files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train set labels extraction\n",
    "\n",
    "with open('data/audio/labels_F.json', 'r') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "files = [f for f in os.listdir('data/audio/embeddingsF_sets/F_train_set') if f.endswith('w2V2.npy')]\n",
    "\n",
    "#Extract the ids from the filenames\n",
    "ids = [f.split('_w2V2.')[0] for f in files]\n",
    "\n",
    "#Extract only the labels that match the ids\n",
    "labels_F_train = {id: data[id] for id in data if id in ids}\n",
    "\n",
    "# Save the extracted labels to a new JSON file\n",
    "with open('data/audio/embeddingsF_sets/labels_F_train.json', 'w') as f:\n",
    "    json.dump(labels_F_train, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "141\n"
     ]
    }
   ],
   "source": [
    "print(len(labels_F_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test set labels extraction\n",
    "\n",
    "with open('data/audio/labels_F.json', 'r') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "files = [f for f in os.listdir('data/audio/embeddingsF_sets/F_test_set') if f.endswith('w2V2.npy')]\n",
    "\n",
    "#Extract the ids from the filenames\n",
    "ids = [f.split('_w2V2.')[0] for f in files]\n",
    "\n",
    "#Extract only the labels that match the ids\n",
    "labels_F_test = {id: data[id] for id in data if id in ids}\n",
    "\n",
    "# Save the extracted labels to a new JSON file\n",
    "with open('data/audio/embeddingsF_sets/labels_F_test.json', 'w') as f:\n",
    "    json.dump(labels_F_test, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30\n"
     ]
    }
   ],
   "source": [
    "print(len(labels_F_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Val set labels extraction\n",
    "\n",
    "with open('data/audio/labels_F.json', 'r') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "files = [f for f in os.listdir('data/audio/embeddingsF_sets/F_val_set') if f.endswith('w2V2.npy')]\n",
    "\n",
    "#Extract the ids from the filenames\n",
    "ids = [f.split('_w2V2.')[0] for f in files]\n",
    "\n",
    "#Extract only the labels that match the ids\n",
    "labels_F_val = {id: data[id] for id in data if id in ids}\n",
    "\n",
    "# Save the extracted labels to a new JSON file\n",
    "with open('data/audio/embeddingsF_sets/labels_F_val.json', 'w') as f:\n",
    "    json.dump(labels_F_val, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32\n"
     ]
    }
   ],
   "source": [
    "print(len(labels_F_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train set labels extraction\n",
    "\n",
    "with open('data/audio/labels_M.json', 'r') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "files = [f for f in os.listdir('data/audio/embeddingsM_sets/M_train_set') if f.endswith('w2V2.npy')]\n",
    "\n",
    "#Extract the ids from the filenames\n",
    "ids = [f.split('_w2V2.')[0] for f in files]\n",
    "\n",
    "#Extract only the labels that match the ids\n",
    "labels_M_train = {id: data[id] for id in data if id in ids}\n",
    "\n",
    "# Save the extracted labels to a new JSON file\n",
    "with open('data/audio/embeddingsM_sets/labels_M_train.json', 'w') as f:\n",
    "    json.dump(labels_M_train, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "312\n"
     ]
    }
   ],
   "source": [
    "print(len(labels_M_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test set labels extraction\n",
    "\n",
    "with open('data/audio/labels_M.json', 'r') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "files = [f for f in os.listdir('data/audio/embeddingsM_sets/M_test_set') if f.endswith('w2V2.npy')]\n",
    "\n",
    "#Extract the ids from the filenames\n",
    "ids = [f.split('_w2V2.')[0] for f in files]\n",
    "\n",
    "#Extract only the labels that match the ids\n",
    "labels_M_test = {id: data[id] for id in data if id in ids}\n",
    "\n",
    "# Save the extracted labels to a new JSON file\n",
    "with open('data/audio/embeddingsM_sets/labels_M_test.json', 'w') as f:\n",
    "    json.dump(labels_M_test, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "68\n"
     ]
    }
   ],
   "source": [
    "print(len(labels_M_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Val set labels extraction\n",
    "\n",
    "with open('data/audio/labels_M.json', 'r') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "files = [f for f in os.listdir('data/audio/embeddingsM_sets/M_val_set') if f.endswith('w2V2.npy')]\n",
    "\n",
    "#Extract the ids from the filenames\n",
    "ids = [f.split('_w2V2.')[0] for f in files]\n",
    "\n",
    "#Extract only the labels that match the ids\n",
    "labels_M_val = {id: data[id] for id in data if id in ids}\n",
    "\n",
    "# Save the extracted labels to a new JSON file\n",
    "with open('data/audio/embeddingsM_sets/labels_M_val.json', 'w') as f:\n",
    "    json.dump(labels_M_val, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "68\n"
     ]
    }
   ],
   "source": [
    "print(len(labels_M_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train set labels extraction\n",
    "\n",
    "with open('data/audio/labels_mixed.json', 'r') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "files = [f for f in os.listdir('data/audio/embeddingsmixed_sets/mixed_train_set') if f.endswith('w2V2.npy')]\n",
    "\n",
    "#Extract the ids from the filenames\n",
    "ids = [f.split('_w2V2.')[0] for f in files]\n",
    "\n",
    "#Extract only the labels that match the ids\n",
    "labels_mixed_train = {id: data[id] for id in data if id in ids}\n",
    "\n",
    "# Save the extracted labels to a new JSON file\n",
    "with open('data/audio/embeddingsmixed_sets/labels_mixed_train.json', 'w') as f:\n",
    "    json.dump(labels_mixed_train, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600\n"
     ]
    }
   ],
   "source": [
    "print(len(labels_mixed_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test set labels extraction\n",
    "\n",
    "with open('data/audio/labels_mixed.json', 'r') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "files = [f for f in os.listdir('data/audio/embeddingsmixed_sets/mixed_test_set') if f.endswith('w2V2.npy')]\n",
    "\n",
    "#Extract the ids from the filenames\n",
    "ids = [f.split('_w2V2.')[0] for f in files]\n",
    "\n",
    "#Extract only the labels that match the ids\n",
    "labels_mixed_test = {id: data[id] for id in data if id in ids}\n",
    "\n",
    "# Save the extracted labels to a new JSON file\n",
    "with open('data/audio/embeddingsmixed_sets/labels_mixed_test.json', 'w') as f:\n",
    "    json.dump(labels_mixed_test, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130\n"
     ]
    }
   ],
   "source": [
    "print(len(labels_mixed_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Val set labels extraction\n",
    "\n",
    "with open('data/audio/labels_mixed.json', 'r') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "files = [f for f in os.listdir('data/audio/embeddingsmixed_sets/mixed_val_set') if f.endswith('w2V2.npy')]\n",
    "\n",
    "#Extract the ids from the filenames\n",
    "ids = [f.split('_w2V2.')[0] for f in files]\n",
    "\n",
    "#Extract only the labels that match the ids\n",
    "labels_mixed_val = {id: data[id] for id in data if id in ids}\n",
    "\n",
    "# Save the extracted labels to a new JSON file\n",
    "with open('data/audio/embeddingsmixed_sets/labels_mixed_val.json', 'w') as f:\n",
    "    json.dump(labels_mixed_val, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130\n"
     ]
    }
   ],
   "source": [
    "print(len(labels_mixed_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DLPROJ",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

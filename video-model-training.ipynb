{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import torch\n",
    "import functions_video_model as functions\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "import torchvision.models as models\n",
    "import cv2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we have to load the video files and select the ones we are interested in. We create different sets of videos:\n",
    "- cleaned_videos: all videos for which the speaker gender has been identified\n",
    "- F_videos: all videos in which the speaker is a woman\n",
    "- M_videos: all videos in which the speaker is a man"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directory containing the videos\n",
    "video_dir = 'data/mmsd_raw_data/utterances_final/'\n",
    "\n",
    "# Get a list of all video files in the directory\n",
    "video_files = [os.path.join(video_dir, f) for f in os.listdir(video_dir) if f.endswith('.mp4')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the JSON files from data labeling\n",
    "with open('data/sarcasm_data.json') as file:\n",
    "    all_data = json.load(file)\n",
    "\n",
    "with open('data/F_data.json') as file:\n",
    "    F_data = json.load(file)\n",
    "\n",
    "with open('data/M_data.json') as file:\n",
    "    M_data = json.load(file)\n",
    "\n",
    "# Extract the keys from the JSON data\n",
    "F_keys = list(F_data.keys())\n",
    "M_keys = list(M_data.keys())\n",
    "\n",
    "# Get a list of video files with utterances by gender\n",
    "F_videos = [video for video in video_files if os.path.splitext(os.path.basename(video))[0] in F_keys]\n",
    "M_videos = [video for video in video_files if os.path.splitext(os.path.basename(video))[0] in M_keys]\n",
    "\n",
    "# Extract sarcasm labels\n",
    "sarcasm_labels = {os.path.splitext(os.path.basename(key))[0]: int(value['sarcasm']) for key, value in all_data.items()}\n",
    "F_sarcasm_labels = {os.path.splitext(os.path.basename(key))[0]: int(value['sarcasm']) for key, value in F_data.items()}\n",
    "M_sarcasm_labels = {os.path.splitext(os.path.basename(key))[0]: int(value['sarcasm']) for key, value in M_data.items()}\n",
    "\n",
    "# Prepare datasets for training\n",
    "mixed_data = [{'video_path': path, 'sarcasm': sarcasm_labels[os.path.splitext(os.path.basename(path))[0]]} for path in video_files]\n",
    "female_data = [{'video_path': path, 'sarcasm': F_sarcasm_labels[os.path.splitext(os.path.basename(path))[0]]} for path in F_videos]\n",
    "male_data = [{'video_path': path, 'sarcasm': M_sarcasm_labels[os.path.splitext(os.path.basename(path))[0]]} for path in M_videos]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's define some classes and functions needed in the training pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class for the PyTorch sarcasm detection Dataset\n",
    "class VideoDataset(Dataset):\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = self.data[idx]\n",
    "        video_path = item['video_path']\n",
    "        sarcasm = int(item['sarcasm'])\n",
    "        video_features = extract_video_features(video_path)\n",
    "        return video_features, sarcasm\n",
    "    \n",
    "\n",
    "# Class for the model\n",
    "class SarcasmDetectionModel(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(SarcasmDetectionModel, self).__init__()\n",
    "        self.i3d = models.video.r3d_18(pretrained=True)\n",
    "        self.i3d.fc = nn.Identity()  # Remove final fully connected layer\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(512, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        features = self.i3d(x)\n",
    "        logits = self.classifier(features)\n",
    "        return logits\n",
    "    \n",
    "\n",
    "\n",
    "def extract_video_features(video_path, sample_rate=5):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    frames = []\n",
    "    frame_count = 0\n",
    "    \n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        # Only add frame to list every 'sample_rate' frames\n",
    "        if frame_count % sample_rate == 0:\n",
    "            frame = cv2.resize(frame, (128, 128))  # Resize frame\n",
    "            frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)  # Convert BGR to RGB\n",
    "            frames.append(frame)\n",
    "        frame_count += 1\n",
    "    \n",
    "    cap.release()\n",
    "    \n",
    "    video_tensor = torch.tensor(frames, dtype=torch.float32)  # Convert frames to tensor\n",
    "    video_tensor = video_tensor.permute(3, 0, 1, 2)  # Should be [C, T, H, W]\n",
    "    \n",
    "    return video_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now train 3 different models: \n",
    "- one model will be trained on all of the videos (video_files)\n",
    "- one model will be trained on videos from female speakers only (F_videos)\n",
    "- one model will be trained on videos from male speakers only (M_videos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\celin\\anaconda3\\envs\\DLproj\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\celin\\anaconda3\\envs\\DLproj\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=R3D_18_Weights.KINETICS400_V1`. You can also use `weights=R3D_18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.6096 , train Acc: 0.6812\n",
      "Epoch 1/5, Train Loss: 0.6096, Train Acc: 0.6812\n",
      "test Loss: 0.6208 , test Acc: 0.6449\n",
      "Epoch 1/5, Test Loss: 0.6208, Test Acc: 0.6449\n",
      "train Loss: 0.4785 , train Acc: 0.7935\n",
      "Epoch 2/5, Train Loss: 0.4785, Train Acc: 0.7935\n",
      "test Loss: 0.9638 , test Acc: 0.6232\n",
      "Epoch 2/5, Test Loss: 0.9638, Test Acc: 0.6232\n",
      "train Loss: 0.3273 , train Acc: 0.8768\n",
      "Epoch 3/5, Train Loss: 0.3273, Train Acc: 0.8768\n",
      "test Loss: 0.6269 , test Acc: 0.7391\n",
      "Epoch 3/5, Test Loss: 0.6269, Test Acc: 0.7391\n",
      "train Loss: 0.2641 , train Acc: 0.8967\n",
      "Epoch 4/5, Train Loss: 0.2641, Train Acc: 0.8967\n",
      "test Loss: 1.5408 , test Acc: 0.5217\n",
      "Epoch 4/5, Test Loss: 1.5408, Test Acc: 0.5217\n",
      "train Loss: 0.2316 , train Acc: 0.9130\n",
      "Epoch 5/5, Train Loss: 0.2316, Train Acc: 0.9130\n",
      "test Loss: 0.7365 , test Acc: 0.7101\n",
      "Epoch 5/5, Test Loss: 0.7365, Test Acc: 0.7101\n"
     ]
    }
   ],
   "source": [
    "# MIXED MODEL\n",
    "\n",
    "# Set seed for reproducibility\n",
    "torch.manual_seed(42)\n",
    "\n",
    "# Set device\n",
    "device = torch.device(\"cpu\")\n",
    "\n",
    "# Set hyperparameters\n",
    "learning_rate = 0.0001\n",
    "num_epochs = 5\n",
    "batch_size = 8\n",
    "weight_decay = 0.05\n",
    "dropout_prob = 0\n",
    "\n",
    "# Split dataset into training and testing\n",
    "dataset = VideoDataset(mixed_data)\n",
    "train_size = int(0.8 * len(dataset))\n",
    "test_size = len(dataset) - train_size\n",
    "train_dataset, test_dataset = random_split(dataset, [train_size, test_size])\n",
    "\n",
    "# Initialize dataloaders\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, collate_fn=functions.custom_collate_fn)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=batch_size, collate_fn=functions.custom_collate_fn)\n",
    "\n",
    "# Initialize the model\n",
    "mixed_model = SarcasmDetectionModel(num_classes=2).to(device)\n",
    "\n",
    "# Define optimizer and criterion\n",
    "optimizer = optim.AdamW(mixed_model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Training loop\n",
    "best_val_acc = 0.0\n",
    "for epoch in range(num_epochs):\n",
    "    train_loss, train_acc = functions.train_epoch(mixed_model, train_dataloader, criterion, optimizer, device)\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f}\")\n",
    "\n",
    "    test_loss, test_acc = functions.evaluate_model(mixed_model, test_dataloader, criterion, device)\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Test Loss: {test_loss:.4f}, Test Acc: {test_acc:.4f}\")\n",
    "\n",
    "# Save model\n",
    "torch.save(mixed_model.state_dict(), 'models/mixed_model_video.pth')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.6506 , train Acc: 0.6481\n",
      "Epoch 1/5, Train Loss: 0.6506, Train Acc: 0.6481\n",
      "test Loss: 0.4810 , test Acc: 0.8537\n",
      "Epoch 1/5, Test Loss: 0.4810, Test Acc: 0.8537\n",
      "train Loss: 0.3936 , train Acc: 0.8333\n",
      "Epoch 2/5, Train Loss: 0.3936, Train Acc: 0.8333\n",
      "test Loss: 0.3998 , test Acc: 0.8293\n",
      "Epoch 2/5, Test Loss: 0.3998, Test Acc: 0.8293\n",
      "train Loss: 0.2877 , train Acc: 0.9074\n",
      "Epoch 3/5, Train Loss: 0.2877, Train Acc: 0.9074\n",
      "test Loss: 0.3236 , test Acc: 0.8049\n",
      "Epoch 3/5, Test Loss: 0.3236, Test Acc: 0.8049\n",
      "train Loss: 0.2171 , train Acc: 0.9383\n",
      "Epoch 4/5, Train Loss: 0.2171, Train Acc: 0.9383\n",
      "test Loss: 0.5551 , test Acc: 0.7317\n",
      "Epoch 4/5, Test Loss: 0.5551, Test Acc: 0.7317\n",
      "train Loss: 0.2077 , train Acc: 0.9259\n",
      "Epoch 5/5, Train Loss: 0.2077, Train Acc: 0.9259\n",
      "test Loss: 0.4882 , test Acc: 0.7561\n",
      "Epoch 5/5, Test Loss: 0.4882, Test Acc: 0.7561\n"
     ]
    }
   ],
   "source": [
    "# FEMALE MODEL\n",
    "\n",
    "# Set seed for reproducibility\n",
    "torch.manual_seed(42)\n",
    "\n",
    "# Set device\n",
    "device = torch.device(\"cpu\")\n",
    "\n",
    "# Set hyperparameters\n",
    "learning_rate = 0.0001\n",
    "num_epochs = 5\n",
    "batch_size = 8\n",
    "weight_decay = 0.05\n",
    "dropout_prob = 0\n",
    "\n",
    "# Split dataset into training and testing\n",
    "dataset = VideoDataset(female_data)\n",
    "train_size = int(0.8 * len(dataset))\n",
    "test_size = len(dataset) - train_size\n",
    "train_dataset, test_dataset = random_split(dataset, [train_size, test_size])\n",
    "\n",
    "# Initialize dataloaders\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, collate_fn=functions.custom_collate_fn)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=batch_size, collate_fn=functions.custom_collate_fn)\n",
    "\n",
    "# Initialize the model\n",
    "F_model = SarcasmDetectionModel(num_classes=2).to(device)\n",
    "\n",
    "# Define optimizer and criterion\n",
    "optimizer = optim.AdamW(F_model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Training loop\n",
    "best_val_acc = 0.0\n",
    "for epoch in range(num_epochs):\n",
    "    train_loss, train_acc = functions.train_epoch(F_model, train_dataloader, criterion, optimizer, device)\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f}\")\n",
    "\n",
    "    test_loss, test_acc = functions.evaluate_model(F_model, test_dataloader, criterion, device)\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Test Loss: {test_loss:.4f}, Test Acc: {test_acc:.4f}\")\n",
    "    \n",
    "# Save model\n",
    "torch.save(F_model.state_dict(), 'models/F_model_video.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.6415 , train Acc: 0.6395\n",
      "Epoch 1/5, Train Loss: 0.6415, Train Acc: 0.6395\n",
      "test Loss: 0.6296 , test Acc: 0.6977\n",
      "Epoch 1/5, Test Loss: 0.6296, Test Acc: 0.6977\n",
      "train Loss: 0.4621 , train Acc: 0.7965\n",
      "Epoch 2/5, Train Loss: 0.4621, Train Acc: 0.7965\n",
      "test Loss: 1.0514 , test Acc: 0.6163\n",
      "Epoch 2/5, Test Loss: 1.0514, Test Acc: 0.6163\n",
      "train Loss: 0.3692 , train Acc: 0.8430\n",
      "Epoch 3/5, Train Loss: 0.3692, Train Acc: 0.8430\n",
      "test Loss: 0.6644 , test Acc: 0.6977\n",
      "Epoch 3/5, Test Loss: 0.6644, Test Acc: 0.6977\n",
      "train Loss: 0.3037 , train Acc: 0.8547\n",
      "Epoch 4/5, Train Loss: 0.3037, Train Acc: 0.8547\n",
      "test Loss: 1.2365 , test Acc: 0.6279\n",
      "Epoch 4/5, Test Loss: 1.2365, Test Acc: 0.6279\n",
      "train Loss: 0.2234 , train Acc: 0.9273\n",
      "Epoch 5/5, Train Loss: 0.2234, Train Acc: 0.9273\n",
      "test Loss: 0.8160 , test Acc: 0.6512\n",
      "Epoch 5/5, Test Loss: 0.8160, Test Acc: 0.6512\n"
     ]
    }
   ],
   "source": [
    "# MALE MODEL\n",
    "\n",
    "# Set seed for reproducibility\n",
    "torch.manual_seed(42)\n",
    "\n",
    "# Set device\n",
    "device = torch.device(\"cpu\")\n",
    "\n",
    "# Set hyperparameters\n",
    "learning_rate = 0.0001\n",
    "num_epochs = 5\n",
    "batch_size = 5\n",
    "weight_decay = 0.05\n",
    "dropout_prob = 0\n",
    "\n",
    "# Split dataset into training and testing\n",
    "dataset = VideoDataset(male_data)\n",
    "train_size = int(0.8 * len(dataset))\n",
    "test_size = len(dataset) - train_size\n",
    "train_dataset, test_dataset = random_split(dataset, [train_size, test_size])\n",
    "\n",
    "# Initialize dataloaders\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, collate_fn=functions.custom_collate_fn)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=batch_size, collate_fn=functions.custom_collate_fn)\n",
    "\n",
    "# Initialize the model\n",
    "M_model = SarcasmDetectionModel(num_classes=2).to(device)\n",
    "\n",
    "# Define optimizer and criterion\n",
    "optimizer = optim.AdamW(M_model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Training loop\n",
    "best_val_acc = 0.0\n",
    "for epoch in range(num_epochs):\n",
    "    train_loss, train_acc = functions.train_epoch(M_model, train_dataloader, criterion, optimizer, device)\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f}\")\n",
    "\n",
    "    test_loss, test_acc = functions.evaluate_model(M_model, test_dataloader, criterion, device)\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Test Loss: {test_loss:.4f}, Test Acc: {test_acc:.4f}\") \n",
    "\n",
    "# Save model\n",
    "torch.save(M_model.state_dict(), 'models/M_model_video.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have created, trained and saved the different models, we will evaluate their performance on the other datasets. Here are the different evaluations we will perform:\n",
    "- performance of mixed_model on the female dataset\n",
    "- performance of mixed_model on the male dataset\n",
    "- performance of F_model on the male dataset\n",
    "- performance of M_model on the female dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DLproj",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-20 20:23:05.037805: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "#Importing the necessary libraries\n",
    "from functions_audio_model_tiny import *\n",
    "from moviepy.editor import VideoFileClip\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from scipy.ndimage import zoom\n",
    "import numpy as np\n",
    "import os\n",
    "import json\n",
    "import librosa\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import SparseCategoricalCrossentropy\n",
    "from tensorflow.keras.metrics import SparseCategoricalAccuracy, Mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "import os\n",
    "\n",
    "class SpectrogramDataset(Dataset):\n",
    "    def __init__(self, spectrogram_dir, labels):\n",
    "        self.spectrogram_dir = spectrogram_dir\n",
    "        self.file_list = [f for f in os.listdir(spectrogram_dir) if f.endswith('_red.npy')]\n",
    "        self.labels = labels  #dictionary mapping base file names to labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.file_list)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        #to get the base name of the file (without the color channel)\n",
    "        base_name = self.file_list[idx].replace('_red.npy', '')\n",
    "\n",
    "        #All colour channels separately\n",
    "        red_channel = np.load(os.path.join(self.spectrogram_dir, base_name + '_red.npy'))\n",
    "        green_channel = np.load(os.path.join(self.spectrogram_dir, base_name + '_green.npy'))\n",
    "        blue_channel = np.load(os.path.join(self.spectrogram_dir, base_name + '_blue.npy'))\n",
    "\n",
    "        #Stack the color channels to create RGB image\n",
    "        spectrogram = np.stack((red_channel, green_channel, blue_channel), axis=2)\n",
    "\n",
    "        #Conversion to tensor\n",
    "        spectrogram = torch.from_numpy(spectrogram)\n",
    "\n",
    "        #Normalisation to range [-1, 1]\n",
    "        spectrogram = (spectrogram - 0.5) * 2\n",
    "\n",
    "        #Label\n",
    "        label = self.labels[base_name]\n",
    "\n",
    "        return spectrogram, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hyperparameters\n",
    "learning_rate = 0.0001\n",
    "#0.001\n",
    "N_EPOCHS = 20\n",
    "#5\n",
    "batchsize = 32\n",
    "#8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load labels for sarcasm detection (from a different file, not part of the spectrograms folder)\n",
    "with open('data/sarcasm_data.json') as f:\n",
    "    text_data = json.load(f)\n",
    "    sarcasm_labels = {k: int(v['sarcasm']) for k, v in text_data.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "690"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sarcasm_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initialisation of the dataset\n",
    "dataset = SpectrogramDataset('data/spectrograms/', sarcasm_labels)\n",
    "\n",
    "# Initialize a DataLoader\n",
    "dataloader = DataLoader(dataset, batch_size=batchsize, shuffle=True)\n",
    "\n",
    "\n",
    "#Splitting the dataset into training and testing data\n",
    "\n",
    "train_size = int(0.8 * len(dataset))  # 80% of the data for training\n",
    "test_size = len(dataset) - train_size  # 20% of the data for testing\n",
    "\n",
    "train_dataset, test_dataset = random_split(dataset, [train_size, test_size])\n",
    "\n",
    "#DataLoaders\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batchsize)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=batchsize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set seed for reproducibility\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# Load pre-trained MobileNetV2 model\n",
    "base_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(1024, activation='relu')(x)\n",
    "predictions = Dense(2, activation='softmax')(x)  #Two classes for classification\n",
    "\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "# Freeze base model layers\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Create the optimizer\n",
    "optimizer = Adam(learning_rate=learning_rate)\n",
    "\n",
    "# Define the loss function\n",
    "loss_fn = SparseCategoricalCrossentropy()\n",
    "\n",
    "# Define the metrics\n",
    "train_acc_metric = SparseCategoricalAccuracy()\n",
    "val_acc_metric = SparseCategoricalAccuracy()\n",
    "\n",
    "train_accs, val_accs, train_losses, val_losses, train_f1s, val_f1s = train_cycle(model, optimizer, loss_fn, train_acc_metric, val_acc_metric, train_dataloader, test_dataloader, epochs=N_EPOCHS)\n",
    "plot_metrics(train_accs, val_accs, train_losses, val_losses, train_f1s, val_f1s)\n",
    "\n",
    "# Save the model weights\n",
    "model.save('models_weights/tiny_bert_spectrograms.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DLPROJ",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
